# Data Engineering for Large Models: Architecture, Algorithms & Projects

[![GitHub Pages](https://img.shields.io/badge/docs-GitHub%20Pages-blue)](https://datascale-ai.github.io/data_engineering_book/en/)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)

**English | [ä¸­æ–‡](README.md)**

## Introduction

> *"Data is the new oil, but only if you know how to refine it."*

In the era of large models, **data quality determines the upper bound of model performance**. Yet systematic resources on LLM data engineering remain extremely scarce â€” most teams are still learning by trial and error.

This book is designed to fill that gap. We systematically cover the complete technical stack from **pre-training data cleaning** to **multimodal alignment**, from **RAG retrieval augmentation** to **synthetic data generation**, including:

- ğŸ§¹ **Pre-training Data Engineering**: Extracting high-quality corpora from massive noisy data sources like Common Crawl
- ğŸ–¼ï¸ **Multimodal Data Processing**: Collection, cleaning, and alignment of image-text pairs, video, and audio data
- ğŸ¯ **Alignment Data Construction**: Automated generation of SFT instruction data, RLHF preference data, and CoT reasoning data
- ğŸ” **RAG Data Pipeline**: Enterprise-grade document parsing, semantic chunking, and multimodal retrieval

Beyond in-depth theoretical explanations, the book includes **5 end-to-end capstone projects** with runnable code and detailed architecture designs for hands-on learning.

**Read Online**: [https://datascale-ai.github.io/data_engineering_book/en/](https://datascale-ai.github.io/data_engineering_book/en/)

## Book Architecture

![Book Architecture](images/structure_en.png)

*A complete data engineering pipeline from raw data to end-to-end applications*

## Table of Contents

```
ğŸ“– 6 Parts, 13 Chapters + 5 Capstone Projects
â”‚
â”œâ”€â”€ Part 1: Infrastructure & Core Concepts
â”‚   â”œâ”€â”€ Chapter 1: Data Revolution in the LLM Era (From Data Ops to AI Ops)
â”‚   â””â”€â”€ Chapter 2: AI-Native Data Stack
â”‚
â”œâ”€â”€ Part 2: Large-Scale Text Pre-training Engineering
â”‚   â”œâ”€â”€ Chapter 3: Data Acquisition
â”‚   â”œâ”€â”€ Chapter 4: Cleaning & Quality Control
â”‚   â””â”€â”€ Chapter 5: Tokenization, Serialization & Efficient Loading
â”‚
â”œâ”€â”€ Part 3: Multimodal Data Engineering
â”‚   â”œâ”€â”€ Chapter 6: Image-Text Pair Processing
â”‚   â”œâ”€â”€ Chapter 7: Recaptioning
â”‚   â””â”€â”€ Chapter 8: Video & Audio Data
â”‚
â”œâ”€â”€ Part 4: Alignment & Synthetic Data Engineering
â”‚   â”œâ”€â”€ Chapter 9: Instruction Fine-tuning Data
â”‚   â”œâ”€â”€ Chapter 10: Synthetic Data
â”‚   â””â”€â”€ Chapter 11: Human Preference Data
â”‚
â”œâ”€â”€ Part 5: Application-level Data Engineering
â”‚   â”œâ”€â”€ Chapter 12: RAG Data Pipeline
â”‚   â””â”€â”€ Chapter 13: Multimodal RAG
â”‚
â””â”€â”€ Part 6: Capstone Projects
    â”œâ”€â”€ Project 1: Building Mini-C4 Pre-training Set
    â”œâ”€â”€ Project 2: Domain Expert SFT (Legal)
    â”œâ”€â”€ Project 3: Building LLaVA Multimodal Instruction Set
    â”œâ”€â”€ Project 4: Synthetic Math/Code Textbook
    â””â”€â”€ Project 5: Multimodal RAG Financial Report Assistant
```

## Key Highlights

### Comprehensive Theory
- **Data-Centric AI** philosophy throughout
- Covers the full LLM data lifecycle: Pre-training â†’ Fine-tuning â†’ RLHF â†’ RAG
- In-depth coverage of Scaling Laws, data quality evaluation, multimodal alignment, and more

### Modern Tech Stack
| Domain | Technologies |
|--------|-------------|
| Distributed Computing | Ray Data, Spark, Dask |
| Data Storage | Parquet, WebDataset, Vector Databases (Milvus/Qdrant) |
| Text Processing | Trafilatura, KenLM, MinHash LSH, fastText Quality Scoring |
| Multimodal | CLIP, ColPali, img2dataset |
| Data Versioning | DVC, LakeFS, Pachyderm |

### Rich Capstone Projects

| Project | Core Technologies | Output |
|---------|-------------------|--------|
| Mini-C4 Pre-training Set | Trafilatura + Ray + MinHash | High-quality text corpus |
| Legal Expert SFT | Self-Instruct + CoT | Domain instruction dataset |
| LLaVA Multimodal | Bbox alignment + multi-image interleaving | Visual instruction dataset |
| Math Textbook | Evol-Instruct + sandbox verification | PoT reasoning dataset |
| Financial Report RAG | ColPali + Qwen-VL | Multimodal QA system |

## Local Development

### Requirements

- Python 3.8+
- MkDocs Material
- mkdocs-static-i18n (i18n support)

### Install & Preview

```bash
# Clone the repository
git clone https://github.com/datascale-ai/data_engineering_book.git
cd data_engineering_book

# Install dependencies
pip install mkdocs-material mkdocs-glightbox pymdown-extensions "mkdocs-static-i18n[material]"

# Local preview
mkdocs serve
```

Visit http://127.0.0.1:8000 to preview the book (with Chinese/English language switcher).

### Build Static Site

```bash
mkdocs build
```

The generated static files are located in the `site/` directory.

## Project Structure

```
data_engineering_book/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ zh/                  # Chinese content
â”‚   â”‚   â”œâ”€â”€ index.md         # Chinese homepage
â”‚   â”‚   â””â”€â”€ part1/ ~ part6/  # All chapters
â”‚   â”œâ”€â”€ en/                  # English content
â”‚   â”‚   â”œâ”€â”€ index.md         # English homepage
â”‚   â”‚   â””â”€â”€ part1/ ~ part6/  # All chapters
â”‚   â”œâ”€â”€ images/              # Image assets (shared)
â”‚   â”œâ”€â”€ stylesheets/         # Custom styles
â”‚   â””â”€â”€ javascripts/         # JavaScript (MathJax etc.)
â”œâ”€â”€ .github/workflows/       # GitHub Actions CI/CD
â”œâ”€â”€ images/                  # Project image assets
â”‚   â”œâ”€â”€ structure_cn.png     # Book architecture diagram (Chinese)
â”‚   â””â”€â”€ structure_en.png     # Book architecture diagram (English)
â”œâ”€â”€ mkdocs.yml               # MkDocs configuration
â”œâ”€â”€ LICENSE                  # License
â”œâ”€â”€ README.md                # ä¸­æ–‡è¯´æ˜
â””â”€â”€ README_en.md             # English README (this file)
```

## Target Audience

- LLM R&D Engineers
- Data Engineers / MLOps Engineers
- AI Product Managers (Technical)
- Researchers interested in LLM data pipelines

## Contributing

Contributions are welcome! Feel free to submit Issues and Pull Requests.

1. Fork this repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Contact

- GitHub Issues: [Submit an issue](https://github.com/datascale-ai/data_engineering_book/issues)
- Read Online: [https://datascale-ai.github.io/data_engineering_book/en/](https://datascale-ai.github.io/data_engineering_book/en/)

---

**If you find this book helpful, please give it a Star!** â­
