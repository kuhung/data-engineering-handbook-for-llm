{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä Multimodal Financial Report RAG Assistant (ColPali + Qwen-VL)\n",
        "This Notebook demonstrates how to build a RAG system capable of \"seeing\" financial charts and tables:\n",
        "1. **Visual Indexing**: Using the ColPali model to convert PDF pages directly into visual embeddings.\n",
        "2. **Multi-page Retrieval**: Retrieving Top-K raw page screenshots based on user queries.\n",
        "3. **Intelligent Analysis**: Sending multiple screenshots to Qwen2.5-VL-72B for deep financial analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Environment Preparation\n",
        "Install `byaldi` (a wrapper for ColPali) and related dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install byaldi openai tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Phase 1: Building the Visual Index\n",
        "Use the ColPali model to index the PDF. The advantage of ColPali is that it bypasses traditional OCR, directly understanding page layouts, charts, and tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from byaldi import RAGMultiModalModel\n",
        "\n",
        "# Optional environment configuration (Offline mode or Mirror site)\n",
        "os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
        "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
        "\n",
        "MODEL_PATH = \"/home/xuxin123/book/project_5_rag/models/colpali-v1_2-merged\"\n",
        "PDF_PATH = \"../data/annual_report_2024_cn.pdf\"\n",
        "INDEX_NAME = \"finance_report_2024\"\n",
        "\n",
        "def build_visual_index():\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        print(\"‚ùå Model folder not found. Please verify the path.\")\n",
        "        return\n",
        "\n",
        "    # Load model (use load_in_4bit=True if GPU memory is limited)\n",
        "    RAG = RAGMultiModalModel.from_pretrained(MODEL_PATH, verbose=1)\n",
        "\n",
        "    print(f\"üìñ Building visual index for {PDF_PATH}...\")\n",
        "    RAG.index(\n",
        "        input_path=PDF_PATH,\n",
        "        index_name=INDEX_NAME,\n",
        "        store_collection_with_index=True,\n",
        "        overwrite=True\n",
        "    )\n",
        "    print(f\"‚úÖ Index saved to: .byaldi/{INDEX_NAME}\")\n",
        "\n",
        "if os.path.exists(PDF_PATH):\n",
        "    build_visual_index()\n",
        "else:\n",
        "    print(\"‚ùå PDF file not found. Please check the path.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Phase 2: Multimodal Chat & Multi-page Augmented Retrieval\n",
        "Configure the LLM client and implement Top-K retrieval logic to handle cross-page financial analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import base64\n",
        "\n",
        "# --- Configuration ---\n",
        "API_KEY = \"YOUR_API_KEY\"\n",
        "BASE_URL = \"https://api.siliconflow.cn/v1\"\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-VL-72B-Instruct\"\n",
        "RETRIEVAL_K = 4 # Retrieve Top 4 pages to mitigate noise from TOC or cover pages\n",
        "\n",
        "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
        "\n",
        "# Load Index\n",
        "try:\n",
        "    RAG = RAGMultiModalModel.from_index(INDEX_NAME)\n",
        "    print(\"‚úÖ Retriever ready\")\n",
        "except: \n",
        "    print(\"‚ùå Please run the previous phase to build the index first\")\n",
        "\n",
        "def ask_finance_helper(query):\n",
        "    # 1. Visual Retrieval\n",
        "    results = RAG.search(query, k=RETRIEVAL_K)\n",
        "    \n",
        "    # 2. Construct Multi-image Payload\n",
        "    messages_content = [\n",
        "        {\n",
        "            \"type\": \"text\", \n",
        "            \"text\": f\"You are a professional CFO. Based on the following {len(results)} screenshots, answer this query: {query}. Please ignore the Table of Contents if present.\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    print(f\"üîç Hit Page Numbers: {[res.page_num for res in results]}\")\n",
        "    \n",
        "    for res in results:\n",
        "        messages_content.append({\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{res.base64}\", \"detail\": \"high\"}\n",
        "        })\n",
        "        \n",
        "    # 3. Cloud Inference\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=[{\"role\": \"user\", \"content\": messages_content}],\n",
        "        temperature=0.1\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Running a Test Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_query = \"What is the revenue growth rate for 2024? Please explain based on the profit and loss statement charts.\"\n",
        "answer = ask_finance_helper(test_query)\n",
        "print(\"\\nü§ñ CFO Assistant Answer:\\n\", answer)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}