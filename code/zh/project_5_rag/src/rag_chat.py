import os
import base64
from byaldi import RAGMultiModalModel
from openai import OpenAI

# === é…ç½®åŒºåŸŸ ===
# 1. ç¡…åŸºæµåŠ¨ API é…ç½®
API_KEY = "sk-lrdpxzsnhsbckhjrzekbrtccomruhcwzyrlwbroqwojtwtsw"  # ä½ çš„å¯†é’¥
BASE_URL = "https://api.siliconflow.cn/v1"

# ä½¿ç”¨ 72B æ¨¡å‹ä»¥è·å¾—æœ€ä½³çš„å›¾è¡¨åˆ†æèƒ½åŠ›
MODEL_NAME = "Qwen/Qwen2.5-VL-72B-Instruct" 

# 2. æœ¬åœ°ç´¢å¼•é…ç½®
INDEX_NAME = "finance_report_2024" 

# 3. æ£€ç´¢é…ç½® (å…³é”®ä¿®æ”¹)
# å¢åŠ æ£€ç´¢é¡µæ•°ï¼Œé˜²æ­¢åªå‘½ä¸­ç›®å½•é¡µã€‚å»ºè®® 3-5 é¡µã€‚
RETRIEVAL_K = 4 

# 4. å¼ºåˆ¶ç¦»çº¿è®¾ç½®
os.environ["HF_HUB_OFFLINE"] = "1"
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–...")
print(f"ğŸ“¡ è¿æ¥äº‘ç«¯æ¨¡å‹: {MODEL_NAME}")

# === åˆå§‹åŒ–å®¢æˆ·ç«¯ ===
client = OpenAI(
    api_key=API_KEY,
    base_url=BASE_URL
)

# === åŠ è½½æœ¬åœ°æ£€ç´¢å™¨ ===
print(f"ğŸ“‚ æ­£åœ¨åŠ è½½æœ¬åœ°ç´¢å¼•: {INDEX_NAME} ...")
try:
    RAG = RAGMultiModalModel.from_index(INDEX_NAME)
    print("âœ… æ£€ç´¢å™¨åŠ è½½æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ æ£€ç´¢å™¨åŠ è½½å¤±è´¥: {e}")
    exit()

def run_chat():
    print("\n" + "="*50)
    print("  å¤šæ¨¡æ€è´¢æŠ¥åŠ©æ‰‹ (APIç‰ˆ - å¤šé¡µå¢å¼ºæ¨¡å¼)")
    print(f"  æ¯æ¬¡æ£€ç´¢: Top-{RETRIEVAL_K} é¡µ (è§£å†³ç›®å½•è·³è½¬é—®é¢˜)")
    print("="*50)

    while True:
        user_query = input("\n>>> è¯·æé—®: ")
        if user_query.lower() in ['quit', 'exit']:
            break
        
        if not user_query.strip():
            continue

        print(f"ğŸ” æ­£åœ¨æ£€ç´¢ Top-{RETRIEVAL_K} ä¸ªç›¸å…³é¡µé¢...")
        
        # 1. æ£€ç´¢ (Local Retrieval)
        try:
            results = RAG.search(user_query, k=RETRIEVAL_K)
        except Exception as e:
            print(f"âŒ æ£€ç´¢å‡ºé”™: {e}")
            continue

        if not results:
            print("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£é¡µé¢ã€‚")
            continue

        # 2. æ„å»ºå¤šæ¨¡æ€è¾“å…¥ (Multi-Image Payload)
        # æˆ‘ä»¬å°†æ£€ç´¢åˆ°çš„ K å¼ å›¾ç‰‡å…¨éƒ¨å–‚ç»™å¤§æ¨¡å‹
        content_payload = []
        
        # å…ˆåŠ å…¥æ–‡å­— Prompt
        content_payload.append({
            "type": "text", 
            "text": f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„CFOåŠ©æ‰‹ã€‚æˆ‘ç»™ä½ æä¾›äº† {len(results)} å¼ è´¢æŠ¥æˆªå›¾ã€‚è¯·æ³¨æ„ï¼šå…¶ä¸­å¯èƒ½åŒ…å«ç›®å½•é¡µï¼Œè¯·å¿½ç•¥ç›®å½•ï¼Œç›´æ¥æ ¹æ®åŒ…å«å…·ä½“æ•°æ®çš„é¡µé¢å›ç­”é—®é¢˜ï¼š{user_query}ã€‚\nå¦‚æœåŒ…å«å›¾è¡¨ï¼Œè¯·è¯¦ç»†è§£è¯»æ•°æ®è¶‹åŠ¿ã€‚"
        })

        print(f"ğŸ“„ å‘½ä¸­é¡µç : ", end="")
        for i, res in enumerate(results):
            page_num = res.page_num
            print(f"[{page_num}] ", end="")
            
            # å°†æ¯ä¸€é¡µå›¾ç‰‡åŠ å…¥ Payload
            content_payload.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{res.base64}", 
                    "detail": "high" # é«˜æ¸…æ¨¡å¼
                }
            })
        print("\nğŸš€ æ­£åœ¨å‘é€ç»™å¤§æ¨¡å‹è¿›è¡Œç»¼åˆåˆ†æ...")

        # 3. ç”Ÿæˆ (Cloud Generation)
        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {
                        "role": "user",
                        "content": content_payload
                    }
                ],
                temperature=0.1,
                max_tokens=2048 # å¢åŠ è¾“å‡ºé•¿åº¦ï¼Œå› ä¸ºåˆ†æå¤šé¡µå†…å®¹å¯èƒ½éœ€è¦æ›´å¤šå­—æ•°
            )
            
            answer = response.choices[0].message.content
            print("\nğŸ¤– è´¢æŠ¥åŠ©æ‰‹å›ç­”:")
            print("-" * 40)
            print(answer)
            print("-" * 40)

        except Exception as e:
            print(f"âŒ API è°ƒç”¨å¤±è´¥: {e}")

if __name__ == "__main__":
    run_chat()