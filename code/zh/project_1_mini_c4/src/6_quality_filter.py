import os
import json
import kenlm
from tqdm import tqdm

# ================= é…ç½® =================
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
DATA_DIR = os.path.join(PROJECT_ROOT, "data", "processed")
MODEL_DIR = os.path.join(PROJECT_ROOT, "models")

INPUT_FILE = os.path.join(DATA_DIR, "data_en.jsonl") 
OUTPUT_FILE = os.path.join(DATA_DIR, "final_data.jsonl")
MODEL_PATH = os.path.join(MODEL_DIR, "en.arpa.bin")

# æ ¹æ®è°ƒè¯•ç»“æœï¼š
# -5.3 ~ -5.9 æ˜¯æ­£å¸¸å¥å­
# -6.4 æ˜¯å¯¼èˆªèœå•åƒåœ¾
# æ‰€ä»¥æˆ‘ä»¬é€‰ -6.0 ä½œä¸ºåˆ†ç•Œçº¿
PERPLEXITY_THRESHOLD = -6.0

# =======================================

def main():
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {INPUT_FILE}")
        return
    
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ æ‰¾ä¸åˆ° KenLM æ¨¡å‹: {MODEL_PATH}")
        return

    print(f"ğŸš€ åŠ è½½ KenLM æ¨¡å‹: {MODEL_PATH} ...")
    model = kenlm.Model(MODEL_PATH)
    print("âœ… æ¨¡å‹åŠ è½½å®Œæ¯•ï¼")

    stats = {
        "total": 0,
        "kept": 0,
        "dropped": 0
    }

    print(f"ğŸ”„ å¼€å§‹è´¨é‡è¿‡æ»¤ (é˜ˆå€¼: {PERPLEXITY_THRESHOLD})...")
    
    # ç”¨äºè°ƒè¯•ï¼šåªæ‰“å°å‰å‡ æ¡çš„å¾—åˆ†
    debug_count = 0 
    
    with open(INPUT_FILE, 'r', encoding='utf-8') as f_in, \
         open(OUTPUT_FILE, 'w', encoding='utf-8') as f_out:
        
        for line in tqdm(f_in, desc="KenLM Filtering"):
            stats["total"] += 1
            try:
                item = json.loads(line)
                text = item.get("text", "")
                
                words = text.split()
                num_words = len(words)
                
                # è¿‡æ»¤æçŸ­æ–‡æœ¬
                if num_words < 3:
                    stats["dropped"] += 1
                    continue

                # --- æ ¸å¿ƒè®¡ç®— ---
                log_score = model.score(text)
                normalized_score = log_score / num_words
                
                # if debug_count < 5:
                #     status = "âœ… ä¿ç•™" if normalized_score > PERPLEXITY_THRESHOLD else "âŒ ä¸¢å¼ƒ"
                #     print(f"\n[è°ƒè¯•] ID: {debug_count+1}")
                #     print(f"  å¾—åˆ†: {normalized_score:.4f}")
                #     print(f"  çŠ¶æ€: {status}")
                #     print(f"  æ–‡æœ¬: {text[:60]}...") # åªæ‰“å°å‰60ä¸ªå­—ç¬¦
                #     debug_count += 1

                # --- åˆ¤å®š ---
                if normalized_score > PERPLEXITY_THRESHOLD:
                    item["perplexity_score"] = normalized_score
                    f_out.write(json.dumps(item, ensure_ascii=False) + '\n')
                    stats["kept"] += 1
                else:
                    stats["dropped"] += 1
                    
            except Exception as e:
                continue

    print("\nğŸ‰ å…¨éƒ¨æµç¨‹ç»“æŸï¼")
    print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    print(f"   è¾“å…¥æ€»æ•°: {stats['total']}")
    print(f"   ğŸ—‘ï¸ ä¸¢å¼ƒ (ä½è´¨é‡): {stats['dropped']} ({(stats['dropped']/stats['total'])*100:.2f}%)")
    print(f"   ğŸ’ ä¿ç•™ (é«˜è´¨é‡): {stats['kept']}")
    print(f"ğŸ’¾ æœ€ç»ˆæ–‡ä»¶: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()