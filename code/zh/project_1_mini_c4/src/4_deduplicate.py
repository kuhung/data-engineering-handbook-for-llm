import ray
import json
import os
from datasketch import MinHash, MinHashLSH
from tqdm import tqdm
import time

# ================= é…ç½® =================
# è‡ªåŠ¨è®¾ç½®è·¯å¾„
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
DATA_DIR = os.path.join(PROJECT_ROOT, "data", "processed")

INPUT_FILE = os.path.join(DATA_DIR, "clean_data.jsonl")  # ä¸Šä¸€æ­¥æ¸…æ´—å®Œçš„æ–‡ä»¶
OUTPUT_FILE = os.path.join(DATA_DIR, "deduplicated_data.jsonl")

# MinHash å‚æ•° (C4 æ ‡å‡†å‚æ•°: num_perm=128)
NUM_PERM = 128 
THRESHOLD = 0.8  # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œè¶…è¿‡ 0.8 è§†ä¸ºé‡å¤

# ================= Ray Actor =================
# æˆ‘ä»¬åˆå§‹åŒ– Rayï¼Œåˆ©ç”¨å•æœºæ‰€æœ‰ CPU æ ¸å¿ƒ
ray.init(ignore_reinit_error=True)

def get_minhash(text, num_perm=128):
    """
    è®¡ç®—ä¸€æ®µæ–‡æœ¬çš„ MinHash ç­¾å
    """
    m = MinHash(num_perm=num_perm)
    # ä½¿ç”¨ç®€å•çš„ shingle (æŒ‰å•è¯åˆ†)
    words = text.split()
    for w in words:
        m.update(w.encode('utf8'))
    return m

@ray.remote
def process_batch(lines, batch_id):
    """
    Ray Worker: å¤„ç†ä¸€æ‰¹æ•°æ®ï¼Œè®¡ç®— MinHash
    è¿”å›: List of (url, minhash_obj, text_content)
    """
    results = []
    for line in lines:
        try:
            item = json.loads(line)
            url = item['url']
            text = item['text']
            
            # è®¡ç®—ç­¾å
            minhash = get_minhash(text, NUM_PERM)
            results.append((url, minhash, text))
        except Exception:
            continue
    return results

# ================= ä¸»æµç¨‹ =================
def main():
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {INPUT_FILE}")
        return

    print("ğŸš€ ç¬¬ä¸€é˜¶æ®µ: å¹¶è¡Œè®¡ç®— MinHash ç­¾å...")
    
    # 1. è¯»å–æ‰€æœ‰æ•°æ®å¹¶åˆ†æ‰¹ (Batching)
    # ä¸ºäº†é¿å…å†…å­˜çˆ†ç‚¸ï¼Œæˆ‘ä»¬æŒ‰å—è¯»å–ï¼Œä½†ä¸ºäº†æ¼”ç¤ºç®€å•ï¼Œè¿™é‡Œå‡è®¾å†…å­˜å¤Ÿå¤§
    # å®é™…ä¸Šåº”è¯¥ç”¨ Ray Dataset æˆ–è€…æµå¼è¯»å–ï¼Œè¿™é‡Œç”¨ç®€æ˜“ç‰ˆåˆ†æ‰¹
    batch_size = 1000
    all_lines = []
    
    # è¯»å–æ–‡ä»¶ (å¦‚æœæ–‡ä»¶æœ‰å‡ åGï¼Œä¸è¦è¿™æ ·è¯»ï¼Œè¦ç”¨æµå¼)
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        all_lines = f.readlines()
    
    total_records = len(all_lines)
    print(f"ğŸ“š æ€»è®°å½•æ•°: {total_records}")

    # å°†æ•°æ®åˆ‡åˆ†æˆå°å—ï¼Œåˆ†å‘ç»™ Ray
    batches = [all_lines[i:i + batch_size] for i in range(0, total_records, batch_size)]
    
    # æäº¤ä»»åŠ¡ç»™ Ray (éé˜»å¡)
    futures = [process_batch.remote(batch, i) for i, batch in enumerate(batches)]
    
    # è·å–ç»“æœ (é˜»å¡ç­‰å¾…æ‰€æœ‰ CPU ç®—å®Œ)
    print("â³ ç­‰å¾… CPU è®¡ç®—ä¸­ ")
    processed_batches = ray.get(futures)
    
    # å±•å¹³ç»“æœ
    # results ç»“æ„: [(url, minhash, text), (url, minhash, text), ...]
    results = [item for batch in processed_batches for item in batch]

    
    print("\nğŸš€ ç¬¬äºŒé˜¶æ®µ: æ„å»º LSH ç´¢å¼•å¹¶å»é‡...")
    # è¿™ä¸€æ­¥é€šå¸¸éš¾ä»¥å¹¶è¡ŒåŒ–ï¼Œå¿…é¡»åœ¨ä¸»è¿›ç¨‹æ„å»ºå…¨å±€ç´¢å¼•
    # å°±åƒæŸ¥å­—å…¸ä¸€æ ·ï¼Œå¿…é¡»æœ‰ä¸€æœ¬å®Œæ•´çš„å­—å…¸
    
    lsh = MinHashLSH(threshold=THRESHOLD, num_perm=NUM_PERM)
    
    unique_records = []
    duplicate_count = 0
    
    # å¼€å§‹éå†å¹¶æŸ¥é‡
    for url, minhash, text in tqdm(results, desc="LSH Deduplication"):
        # æŸ¥è¯¢ LSH æ¡¶é‡Œæ˜¯å¦æœ‰ç›¸ä¼¼çš„
        # query è¿”å›çš„æ˜¯å·²ç»å­˜åœ¨äºæ¡¶é‡Œçš„ key (è¿™é‡Œæˆ‘ä»¬ç”¨ url å½“ key)
        duplicates = lsh.query(minhash)
        
        if len(duplicates) > 0:
            # å‘ç°é‡å¤ï¼
            duplicate_count += 1
            # ç­–ç•¥ï¼šç®€å•çš„ä¸¢å¼ƒå½“å‰è¿™æ¡ï¼Œä¿ç•™æ¡¶é‡Œé‚£æ¡
            # ä½ ä¹Ÿå¯ä»¥æ ¹æ®æ—¶é—´æˆ³ä¿ç•™æœ€æ–°çš„ï¼Œè¿™é‡Œä»ç®€
        else:
            # æ²¡æœ‰é‡å¤ï¼Œæ’å…¥æ¡¶ä¸­
            lsh.insert(url, minhash)
            unique_records.append({"url": url, "text": text})

    print(f"\nâœ… å»é‡å®Œæˆï¼")
    print(f"ğŸ—‘ï¸ å‘ç°é‡å¤: {duplicate_count}")
    print(f"ğŸ’ å‰©ä½™æœ‰æ•ˆ: {len(unique_records)}")
    
    # ä¿å­˜ç»“æœ
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        for item in unique_records:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    ray.shutdown()

if __name__ == "__main__":
    main()