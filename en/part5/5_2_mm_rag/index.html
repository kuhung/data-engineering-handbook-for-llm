<!DOCTYPE html><html lang="en" class="no-js"><head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="大模型数据工程：架构、算法及项目实战">
      
      
        <meta name="author" content="ustc">
      
      
        <link rel="canonical" href="https://datascale-ai.github.io/data_engineering_book/en/part5/5_2_mm_rag/">
      
      
        <link rel="prev" href="../5_1_rag_pipeline/">
      
      
        <link rel="next" href="../../part6/6_1_mini_c4/">
      
      
        
          <link rel="alternate" href="../../../part5/5_2_mm_rag/" hreflang="zh">
        
          <link rel="alternate" href="./" hreflang="en">
        
          <link rel="alternate" href="../../../ja/part5/5_2_mm_rag/" hreflang="ja">
        
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.2">
    
    
      
        <title>Chapter 13: Multimodal RAG - Data Engineering for Large Models: Architecture, Algorithms &amp; Projects</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"><script src="../../../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="red">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#chapter-13-multimodal-rag" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../" title="Data Engineering for Large Models: Architecture, Algorithms &amp; Projects" class="md-header__button md-logo" aria-label="Data Engineering for Large Models: Architecture, Algorithms &amp; Projects" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Data Engineering for Large Models: Architecture, Algorithms &amp; Projects
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Chapter 13: Multimodal RAG
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="red" aria-label="Switch to dark mode" type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"></path></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="red" aria-label="Switch to light mode" type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"></path></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="../../../part5/5_2_mm_rag/" hreflang="zh" class="md-select__link">
              简体中文
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="./" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="../../../ja/part5/5_2_mm_rag/" hreflang="ja" class="md-select__link">
              日本語
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/datascale-ai/data_engineering_book/tree/main" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../" title="Data Engineering for Large Models: Architecture, Algorithms &amp; Projects" class="md-nav__button md-logo" aria-label="Data Engineering for Large Models: Architecture, Algorithms &amp; Projects" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    Data Engineering for Large Models: Architecture, Algorithms &amp; Projects
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/datascale-ai/data_engineering_book/tree/main" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Table of Contents
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2">
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 1: Infrastructure &amp; Core Concepts
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 1: Infrastructure &amp; Core Concepts
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part1/1_1_data_change/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 1: Data Revolution in the LLM Era
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part1/1_2_data_infra/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 2: Data Infrastructure Selection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3">
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 2: Text Pre-training Data Engineering
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 2: Text Pre-training Data Engineering
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part2/2_1_data_acquisition/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 3: Data Acquisition
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part2/2_2_cleaning_denoising/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 4: Cleaning &amp; Deduplication
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part2/2_3_tokenization_serialization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 5: Tokenization &amp; Serialization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4">
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 3: Multimodal Data Engineering
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 3: Multimodal Data Engineering
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part3/3_1_image_text_pairs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 6: Image-Text Pair Processing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part3/3_2_recaptioning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 7: Recaptioning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part3/3_3_video_audio/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 8: Video &amp; Audio Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5">
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 4: Alignment &amp; Synthetic Data Engineering
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 4: Alignment &amp; Synthetic Data Engineering
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part4/4_1_sft_data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 9: Instruction Fine-tuning Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part4/4_2_synthetic_data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 10: Synthetic Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part4/4_3_preference_data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 11: Human Preference Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 5: Application-level Data Engineering
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 5: Application-level Data Engineering
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5_1_rag_pipeline/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 12: RAG Data Pipeline
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Chapter 13: Multimodal RAG
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 13: Multimodal RAG
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#chapter-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#130-learning-objectives" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.0 Learning Objectives
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Scenario Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#131-cross-modal-retrieval-breaking-text-image-barriers" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.1 Cross-Modal Retrieval: Breaking Text-Image Barriers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.1 Cross-Modal Retrieval: Breaking Text-Image Barriers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1311-core-principle-contrastive-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.1.1 Core Principle: Contrastive Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1312-technology-selection-clip-vs-siglip" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.1.2 Technology Selection: CLIP vs. SigLIP
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#132-colpali-architecture-in-practice-ending-the-ocr-nightmare" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.2 ColPali Architecture in Practice: Ending the OCR Nightmare
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.2 ColPali Architecture in Practice: Ending the OCR Nightmare">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1321-core-principle-late-interaction-of-vision-language-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.2.1 Core Principle: Late Interaction of Vision-Language Models
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#133-engineering-implementation-building-hybrid-multimodal-retrieval-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.3 Engineering Implementation: Building Hybrid Multimodal Retrieval Pipeline
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.3 Engineering Implementation: Building Hybrid Multimodal Retrieval Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1331-overall-architecture-and-data-flow" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.3.1 Overall Architecture and Data Flow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1332-core-code-multimodal-indexing-and-scoring" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.3.2 Core Code: Multimodal Indexing and Scoring
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1333-performance-optimization-binary-quantization-bq" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.3.3 Performance Optimization: Binary Quantization (BQ)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#134-performance-and-evaluation-performance-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.4 Performance and Evaluation (Performance &amp; Evaluation)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.4 Performance and Evaluation (Performance &amp; Evaluation)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1341-evaluation-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.4.1 Evaluation Metrics
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1342-benchmarks" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.4.2 Benchmarks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.4.2 Benchmarks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-accuracy-comparison-recall5" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Accuracy Comparison (Recall@5)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-latency-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Latency Comparison
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1343-interpretability-where-is-the-model-looking" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.4.3 Interpretability: Where is the Model Looking?
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#135-common-misconceptions-and-pitfalls" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.5 Common Misconceptions and Pitfalls
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chapter-summary_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading" class="md-nav__link">
    <span class="md-ellipsis">
      
        Further Reading
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7">
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 6: Capstone Projects
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 6: Capstone Projects
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_1_mini_c4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 1: Building Mini-C4 Pre-training Set
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_2_legal_sft/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 2: Domain Expert SFT
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_3_llava_instruct/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 3: Building LLaVA Multimodal Instruction Set
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_4_synthetic_textbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 4: Synthetic Math/Code Textbook
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_5_mm_rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 5: Multimodal RAG Financial Report Assistant
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#chapter-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#130-learning-objectives" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.0 Learning Objectives
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Scenario Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#131-cross-modal-retrieval-breaking-text-image-barriers" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.1 Cross-Modal Retrieval: Breaking Text-Image Barriers
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.1 Cross-Modal Retrieval: Breaking Text-Image Barriers">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1311-core-principle-contrastive-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.1.1 Core Principle: Contrastive Learning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1312-technology-selection-clip-vs-siglip" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.1.2 Technology Selection: CLIP vs. SigLIP
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#132-colpali-architecture-in-practice-ending-the-ocr-nightmare" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.2 ColPali Architecture in Practice: Ending the OCR Nightmare
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.2 ColPali Architecture in Practice: Ending the OCR Nightmare">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1321-core-principle-late-interaction-of-vision-language-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.2.1 Core Principle: Late Interaction of Vision-Language Models
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#133-engineering-implementation-building-hybrid-multimodal-retrieval-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.3 Engineering Implementation: Building Hybrid Multimodal Retrieval Pipeline
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.3 Engineering Implementation: Building Hybrid Multimodal Retrieval Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1331-overall-architecture-and-data-flow" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.3.1 Overall Architecture and Data Flow
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1332-core-code-multimodal-indexing-and-scoring" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.3.2 Core Code: Multimodal Indexing and Scoring
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1333-performance-optimization-binary-quantization-bq" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.3.3 Performance Optimization: Binary Quantization (BQ)
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#134-performance-and-evaluation-performance-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.4 Performance and Evaluation (Performance &amp; Evaluation)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.4 Performance and Evaluation (Performance &amp; Evaluation)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1341-evaluation-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.4.1 Evaluation Metrics
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1342-benchmarks" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.4.2 Benchmarks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.4.2 Benchmarks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-accuracy-comparison-recall5" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Accuracy Comparison (Recall@5)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-latency-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. Latency Comparison
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1343-interpretability-where-is-the-model-looking" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.4.3 Interpretability: Where is the Model Looking?
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#135-common-misconceptions-and-pitfalls" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.5 Common Misconceptions and Pitfalls
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chapter-summary_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading" class="md-nav__link">
    <span class="md-ellipsis">
      
        Further Reading
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="chapter-13-multimodal-rag">Chapter 13: Multimodal RAG<a class="headerlink" href="#chapter-13-multimodal-rag" title="Permanent link">¶</a></h1>
<hr>
<h2 id="chapter-summary">Chapter Summary<a class="headerlink" href="#chapter-summary" title="Permanent link">¶</a></h2>
<p>With text RAG competition at its peak, multimodal has become the new battlefield. Enterprise documents often contain large amounts of <strong>charts, flowcharts, screenshots</strong>—traditional RAG typically chooses OCR to text or ignores images, causing key information loss. This chapter breaks through "pure text" limits to build systems that can "see" data. We start from basic CLIP/SigLIP cross-modal retrieval, delve into the disruptive <strong>ColPali architecture</strong>, and implement an end-to-end retrieval pipeline including <strong>Binary Quantization (BQ)</strong> and <strong>Late Interaction scoring logic</strong>.</p>
<h2 id="130-learning-objectives">13.0 Learning Objectives<a class="headerlink" href="#130-learning-objectives" title="Permanent link">¶</a></h2>
<ul>
<li><strong>Understand multimodal vector space</strong>: Master CLIP and SigLIP contrastive loss principles; understand how text and images align in the same vector space.</li>
<li><strong>Master ColPali architecture</strong>: Understand Late Interaction mechanism; learn to use <code>colpali-v1.2-merged</code> for complex PDF tables and charts.</li>
<li><strong>Engineering capability</strong>: Write Python code implementing <strong>MaxSim scoring</strong> algorithm and use <strong>Binary Quantization</strong> to reduce storage cost 32x.</li>
<li><strong>Visualization verification</strong>: Verify model interpretability through attention heatmaps.</li>
</ul>
<hr>
<h2 id="scenario-introduction">Scenario Introduction<a class="headerlink" href="#scenario-introduction" title="Permanent link">¶</a></h2>
<p>You're maintaining a semiconductor equipment repair knowledge base. Technical manuals are full of complex circuit diagrams and device structure diagrams.
Field engineer requests: "Help me find the 'mainboard power supply module' wiring diagram."</p>
<ul>
<li><strong>Traditional RAG (Text-only)</strong>: Retrieved text description "mainboard power supply refer to Figure 3-12," but system cannot return the image, or OCR turned the circuit diagram into garbled characters (e.g., <code>---||---</code>), leaving the engineer staring at text helplessly.</li>
<li><strong>Multimodal RAG</strong>: System not only understands user's text intent but directly retrieves PDF page screenshots containing the circuit diagram, and <strong>precisely highlights</strong> the power supply module region.</li>
</ul>
<p>This is the qualitative leap from "reading" to "seeing." In many industrial and financial scenarios, one image's information density far exceeds a thousand words.</p>
<hr>
<h2 id="131-cross-modal-retrieval-breaking-text-image-barriers">13.1 Cross-Modal Retrieval: Breaking Text-Image Barriers<a class="headerlink" href="#131-cross-modal-retrieval-breaking-text-image-barriers" title="Permanent link">¶</a></h2>
<p>To achieve "text-to-image search" or "image-to-text search," we need a model that understands both modalities.</p>
<h3 id="1311-core-principle-contrastive-learning">13.1.1 Core Principle: Contrastive Learning<a class="headerlink" href="#1311-core-principle-contrastive-learning" title="Permanent link">¶</a></h3>
<p>OpenAI's CLIP (Contrastive Language-Image Pre-training) is the cornerstone. Its training logic is simple and brutal:
1.  Collect hundreds of millions of (image, text) pairs.
2.  Extract vectors via <strong>image encoder</strong> and <strong>text encoder</strong>.
3.  <strong>Pull</strong> matching pair vectors closer, <strong>push</strong> non-matching pairs apart.</p>
<p>Result: A "dog" photo vector and "Dog" text vector are mathematically very close in space.</p>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part5/%E5%9B%BE13_1_CLIP%E6%9E%B6%E6%9E%84.png" data-desc-position="bottom"><img alt="Figure 13-1: CLIP Multimodal Vector Space Diagram" src="../../../images/part5/%E5%9B%BE13_1_CLIP%E6%9E%B6%E6%9E%84.png"></a></p>
<!-- ![Figure 13-1: CLIP Multimodal Vector Space Diagram](images/Chapter 13/图13_1_CLIP架构.png) -->

<p><em>Figure 13-1: CLIP Architecture —— Text and images are mapped to the same high-dimensional sphere; cosine similarity determines association</em></p>
<h3 id="1312-technology-selection-clip-vs-siglip">13.1.2 Technology Selection: CLIP vs. SigLIP<a class="headerlink" href="#1312-technology-selection-clip-vs-siglip" title="Permanent link">¶</a></h3>
<p>Although CLIP is most famous, for engineering we have better choices. Google's <strong>SigLIP (Sigmoid Loss for Language Image Pre-training)</strong> surpasses CLIP on multiple metrics.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">OpenAI CLIP</th>
<th style="text-align: left;">Google SigLIP</th>
<th style="text-align: left;">Architect Recommendation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Loss Function</strong></td>
<td style="text-align: left;">Softmax (global normalization)</td>
<td style="text-align: left;"><strong>Sigmoid</strong> (independent binary classification)</td>
<td style="text-align: left;">Sigmoid has higher memory efficiency; suitable for large batch training</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Chinese Support</strong></td>
<td style="text-align: left;">Weak (mainly English)</td>
<td style="text-align: left;"><strong>Better</strong> (multilingual version)</td>
<td style="text-align: left;">Must use multilingual checkpoint</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Resolution</strong></td>
<td style="text-align: left;">Usually 224x224</td>
<td style="text-align: left;">Supports dynamic resolution</td>
<td style="text-align: left;">Complex charts choose high resolution (384+) model</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Recommendation</strong>: For new systems in 2025, prioritize <strong>SigLIP</strong> or Meta's <strong>DINOv2</strong> (strong pure visual features).</p>
</blockquote>
<hr>
<h2 id="132-colpali-architecture-in-practice-ending-the-ocr-nightmare">13.2 ColPali Architecture in Practice: Ending the OCR Nightmare<a class="headerlink" href="#132-colpali-architecture-in-practice-ending-the-ocr-nightmare" title="Permanent link">¶</a></h2>
<p>For PDF document retrieval, CLIP has a fatal weakness: it excels at natural images (cats, dogs, scenery) but has poor understanding of <strong>rich-text images</strong> (document pages with dense text, tables).
Traditional approach is <code>PDF -&gt; OCR -&gt; Text Embedding</code>, but OCR loses layout information and is helpless with charts.</p>
<p><strong>ColPali (ColBERT + PaliGemma)</strong> proposes a revolutionary idea: <strong>No OCR—treat PDF pages directly as images.</strong></p>
<h3 id="1321-core-principle-late-interaction-of-vision-language-models">13.2.1 Core Principle: Late Interaction of Vision-Language Models<a class="headerlink" href="#1321-core-principle-late-interaction-of-vision-language-models" title="Permanent link">¶</a></h3>
<p>ColPali combines Vision-Language Model (VLM) and ColBERT retrieval mechanism.</p>
<ol>
<li><strong>Patch Embedding</strong>: Split document image into small patches; each patch generates a vector. One image may correspond to 1024 vectors.</li>
<li><strong>Late Interaction (MaxSim)</strong>: At retrieval, compute each Query token vector against all document Patch vectors, take maximum similarity.</li>
</ol>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part5/%E5%9B%BE13_2_ColPali%E5%AF%B9%E6%AF%94.png" data-desc-position="bottom"><img alt="Figure 13-2: ColPali vs OCR Comparison" src="../../../images/part5/%E5%9B%BE13_2_ColPali%E5%AF%B9%E6%AF%94.png"></a></p>
<!-- ![Figure 13-2: ColPali vs OCR Comparison](images/Chapter 13/图13_2_ColPali对比.png) -->

<p><em>Figure 13-2: Bad Case (Left) vs Good Case (Right) —— Left: OCR turns table into garbled characters; Right: ColPali directly aligns Query with table rows at image level</em></p>
<hr>
<h2 id="133-engineering-implementation-building-hybrid-multimodal-retrieval-pipeline">13.3 Engineering Implementation: Building Hybrid Multimodal Retrieval Pipeline<a class="headerlink" href="#133-engineering-implementation-building-hybrid-multimodal-retrieval-pipeline" title="Permanent link">¶</a></h2>
<p>This section implements a retrieval system framework compatible with <strong>SigLIP (natural images)</strong> and <strong>ColPali (document images)</strong>.</p>
<h3 id="1331-overall-architecture-and-data-flow">13.3.1 Overall Architecture and Data Flow<a class="headerlink" href="#1331-overall-architecture-and-data-flow" title="Permanent link">¶</a></h3>
<p>Before coding, we need to clarify data flow. This is no longer simple "text in, text out."</p>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part5/%E5%9B%BE13_3_%E5%A4%9A%E6%A8%A1%E6%80%81%E6%B5%81%E6%B0%B4%E7%BA%BF.png" data-desc-position="bottom"><img alt="Figure 13-3: Multimodal RAG End-to-End Pipeline" src="../../../images/part5/%E5%9B%BE13_3_%E5%A4%9A%E6%A8%A1%E6%80%81%E6%B5%81%E6%B0%B4%E7%BA%BF.png"></a></p>
<!-- ![Figure 13-3: Multimodal RAG End-to-End Pipeline](images/Chapter 13/图13_3_多模态流水线.png) -->

<p><em>Figure 13-3: End-to-End Pipeline —— Left: index flow (PDF to image -&gt; Vision Encoder -&gt; Quantization -&gt; Vector DB); Right: retrieval flow (Query -&gt; Text Encoder -&gt; MaxSim scoring -&gt; Re-rank)</em></p>
<h3 id="1332-core-code-multimodal-indexing-and-scoring">13.3.2 Core Code: Multimodal Indexing and Scoring<a class="headerlink" href="#1332-core-code-multimodal-indexing-and-scoring" title="Permanent link">¶</a></h3>
<p>We define <code>MultimodalIndexer</code>. For practical capability, we need not just "vectorization (Embedding)" logic but explicit "scoring" logic—ColPali retrieval cannot simply rely on vector database Cosine Similarity.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoProcessor</span><span class="p">,</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">SiglipProcessor</span><span class="p">,</span> <span class="n">SiglipModel</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="k">class</span><span class="w"> </span><span class="nc">MultimodalIndexer</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">    Multimodal indexer: Unified wrapper for SigLIP (natural images) and ColPali (document images)</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">    """</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_colpali</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_colpali</span> <span class="o">=</span> <span class="n">use_colpali</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_colpali</span><span class="p">:</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>             <span class="c1"># [Key decision] Use Merged version (combines visual encoder and language model into single checkpoint)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>             <span class="c1"># Simplified for unified loading and deployment</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>            <span class="kn">from</span><span class="w"> </span><span class="nn">colpali_engine.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">ColPali</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>            <span class="kn">from</span><span class="w"> </span><span class="nn">colpali_engine.utils.processing_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">ColPaliProcessor</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>            <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"vidore/colpali-v1.2-merged"</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loading ColPali model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">..."</span><span class="p">)</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ColPali</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>                <span class="n">model_name</span><span class="p">,</span> 
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>                <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> 
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>                <span class="n">device_map</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>            <span class="p">)</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">ColPaliProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>            <span class="c1"># Load SigLIP</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>            <span class="n">model_name</span> <span class="o">=</span> <span class="s2">"google/siglip-so400m-patch14-384"</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loading SigLIP model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">..."</span><span class="p">)</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">SiglipModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">SiglipProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">embed_images</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_paths</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a><span class="w">        </span><span class="sd">"""Step 1: Image vectorization"""</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>        <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">"RGB"</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">image_paths</span><span class="p">]</span>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_colpali</span><span class="p">:</span>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>                <span class="c1"># ColPali: Returns List[Tensor], each shape (Num_Patches, 128)</span>
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>                <span class="n">batch_images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="o">.</span><span class="n">process_images</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>                <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch_images</span><span class="p">)</span> 
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>                <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span> 
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>                <span class="c1"># SigLIP: Returns (Batch, Hidden_Dim)</span>
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>                <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>                <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_image_features</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>                <span class="k">return</span> <span class="p">(</span><span class="n">features</span> <span class="o">/</span> <span class="n">features</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">embed_query</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a><span class="w">        </span><span class="sd">"""Step 2: Query text vectorization"""</span>
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_colpali</span><span class="p">:</span>
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>                <span class="n">batch_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="o">.</span><span class="n">process_queries</span><span class="p">([</span><span class="n">text</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch_text</span><span class="p">)</span> <span class="c1"># Returns (1, Query_Tokens, 128)</span>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>                <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="p">[</span><span class="n">text</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>                <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_text_features</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>                <span class="k">return</span> <span class="n">features</span> <span class="o">/</span> <span class="n">features</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">score_colpali</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query_emb</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">doc_embeddings_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a><span class="w">        </span><span class="sd">"""</span>
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a><span class="sd">        Step 3: ColPali core scoring logic (Late Interaction / MaxSim)</span>
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a>
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a><span class="sd">            query_emb: (1, Q_Tokens, Dim)</span>
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a><span class="sd">            doc_embeddings_list: List of (D_Tokens, Dim) - patches per page may vary</span>
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a><span class="sd">        """</span>
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a>        <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>        <span class="c1"># Remove Query batch dimension -&gt; (Q_Tokens, Dim)</span>
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a>        <span class="n">Q</span> <span class="o">=</span> <span class="n">query_emb</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> 
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a>
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a>        <span class="k">for</span> <span class="n">D</span> <span class="ow">in</span> <span class="n">doc_embeddings_list</span><span class="p">:</span>
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>            <span class="c1"># 1. Compute interaction matrix: </span>
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a>            <span class="c1"># (Q_Tokens, Dim) @ (Dim, D_Tokens) -&gt; (Q_Tokens, D_Tokens)</span>
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a>            <span class="c1"># Using einsum: q=query tokens, d=doc patches, h=hidden dim</span>
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a>            <span class="n">sim_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">"qh,dh-&gt;qd"</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#__codelineno-0-81"></a>            <span class="c1"># 2. MaxSim: For each Query token, find max similarity among all document patches</span>
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#__codelineno-0-82"></a>            <span class="n">max_sim_per_token</span> <span class="o">=</span> <span class="n">sim_matrix</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#__codelineno-0-83"></a>
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#__codelineno-0-84"></a>            <span class="c1"># 3. Sum: Sum all Query token max similarities for final score</span>
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#__codelineno-0-85"></a>            <span class="n">score</span> <span class="o">=</span> <span class="n">max_sim_per_token</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#__codelineno-0-86"></a>            <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#__codelineno-0-87"></a>
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#__codelineno-0-88"></a>        <span class="k">return</span> <span class="n">scores</span>
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#__codelineno-0-89"></a>
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#__codelineno-0-90"></a><span class="c1"># --- Usage Example ---</span>
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#__codelineno-0-91"></a><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#__codelineno-0-92"></a>    <span class="n">indexer</span> <span class="o">=</span> <span class="n">MultimodalIndexer</span><span class="p">(</span><span class="n">use_colpali</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#__codelineno-0-93"></a>    <span class="c1"># Assume we have embeddings</span>
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#__codelineno-0-94"></a>    <span class="c1"># scores = indexer.score_colpali(q_emb, [doc_emb1, doc_emb2])</span>
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#__codelineno-0-95"></a>    <span class="c1"># top_k = np.argsort(scores)[::-1]</span>
</code></pre></div>
<h2 id="1333-performance-optimization-binary-quantization-bq">13.3.3 Performance Optimization: Binary Quantization (BQ)<a class="headerlink" href="#1333-performance-optimization-binary-quantization-bq" title="Permanent link">¶</a></h2>
<p>ColPali's biggest engineering pain is <strong>storage explosion</strong>.</p>
<ul>
<li><strong>Traditional Embedding</strong>: 1 page = 1 vector (4KB float32).</li>
<li><strong>ColPali</strong>: 1 page = 1032 vectors (512KB float16).</li>
</ul>
<p>Indexing 1 million PDF pages needs 500GB memory—often unacceptable in practice.</p>
<p><strong>Solution</strong>: Use Binary Quantization, compressing float16 to 1-bit.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">quantize_embeddings</span><span class="p">(</span><span class="n">embeddings</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="sd">    Principle: Values &gt; 0 become 1, &lt;= 0 become 0.</span>
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="sd">    Storage compression: 32x (float32 -&gt; int1)</span>
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="sd">    Precision loss: Recall@5 drops less than 2%</span>
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="sd">    """</span>
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>    <span class="c1"># Simple binarization</span>
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>    <span class="n">binary_emb</span> <span class="o">=</span> <span class="p">(</span><span class="n">embeddings</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> 
<a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>
<a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>    <span class="c1"># For actual storage can use packbits to compress to uint8</span>
<a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>    <span class="c1"># packed = np.packbits(binary_emb.cpu().numpy().astype(np.uint8), axis=-1)</span>
<a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>
<a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>    <span class="k">return</span> <span class="n">binary_emb</span>
<a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>
<a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a><span class="k">def</span><span class="w"> </span><span class="nf">score_binary</span><span class="p">(</span><span class="n">query_emb</span><span class="p">,</span> <span class="n">binary_doc_emb</span><span class="p">):</span>
<a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a><span class="sd">    Binary vector scoring typically uses Hamming Distance or bitwise operations</span>
<a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a><span class="sd">    but in ColPali, usually keep Query as float, only quantize Doc—</span>
<a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a><span class="sd">    then dot product becomes simple add/subtract, greatly accelerating computation.</span>
<a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a><span class="sd">    """</span>
<a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a>    <span class="k">pass</span> 
</code></pre></div>
<blockquote>
<p><strong>Architecture decision</strong>: In production, recommend databases supporting Binary Vector (Qdrant, Vespa) or dedicated index libraries (USearch)—they can leverage CPU instructions (AVX-512 POPCNT) for ultra-fast matching at bottom layer.</p>
</blockquote>
<hr>
<h2 id="134-performance-and-evaluation-performance-evaluation">13.4 Performance and Evaluation (Performance &amp; Evaluation)<a class="headerlink" href="#134-performance-and-evaluation-performance-evaluation" title="Permanent link">¶</a></h2>
<p>Multimodal RAG evaluation isn't just "finding correctly" but "why it was found."</p>
<h3 id="1341-evaluation-metrics">13.4.1 Evaluation Metrics<a class="headerlink" href="#1341-evaluation-metrics" title="Permanent link">¶</a></h3>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Applicable Scenario</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Recall@K</strong></td>
<td>General retrieval</td>
<td>Probability that top K results contain correct image.</td>
</tr>
<tr>
<td><strong>NDCG@10</strong></td>
<td>Ranking quality</td>
<td>Higher score for more relevant images ranked higher.</td>
</tr>
<tr>
<td><strong>OCR-Free Efficiency</strong></td>
<td>ColPali scenario</td>
<td>Time/cost savings ratio vs. OCR + Dense Retrieval.</td>
</tr>
</tbody>
</table>
<h3 id="1342-benchmarks">13.4.2 Benchmarks<a class="headerlink" href="#1342-benchmarks" title="Permanent link">¶</a></h3>
<ul>
<li><strong>Test environment</strong>: Intel Xeon Gold 6226R, NVIDIA RTX 3090.</li>
<li><strong>Dataset</strong>: ViDoRe Benchmark (complex financial statements).</li>
</ul>
<h4 id="1-accuracy-comparison-recall5">1. Accuracy Comparison (Recall@5)<a class="headerlink" href="#1-accuracy-comparison-recall5" title="Permanent link">¶</a></h4>
<ul>
<li><strong>Unstructured OCR + BGE-M3</strong>: 43% (table structure loss is main cause).</li>
<li><strong>ColPali v1.2</strong>: 81% (direct visual layout understanding).</li>
</ul>
<h4 id="2-latency-comparison">2. Latency Comparison<a class="headerlink" href="#2-latency-comparison" title="Permanent link">¶</a></h4>
<ul>
<li><strong>SigLIP (Dense)</strong>: &lt; 20ms / query.</li>
<li><strong>ColPali (Late Interaction)</strong>: ~150ms / query.</li>
</ul>
<p><strong>Conclusion</strong>: ColPali suitable for Re-rank or high-quality retrieval; massive data needs quantization.</p>
<h3 id="1343-interpretability-where-is-the-model-looking">13.4.3 Interpretability: Where is the Model Looking?<a class="headerlink" href="#1343-interpretability-where-is-the-model-looking" title="Permanent link">¶</a></h3>
<p>ColPali's another advantage is <strong>interpretability</strong>. By visualizing the interaction matrix from MaxSim computation, we can generate heatmaps showing exactly which document region the model attended to.</p>
<hr>
<h2 id="135-common-misconceptions-and-pitfalls">13.5 Common Misconceptions and Pitfalls<a class="headerlink" href="#135-common-misconceptions-and-pitfalls" title="Permanent link">¶</a></h2>
<ul>
<li><strong>Misconception 1: "All images are worth indexing"</strong></li>
<li>Web page or document icons, decorative lines, header/footer logos produce massive noise.</li>
<li>
<p><strong>Fix</strong>: Add "junk image classifier" or rule-based filter before indexing (e.g., discard &lt; 5KB or extreme aspect ratio images).</p>
</li>
<li>
<p><strong>Misconception 2: "Ignore Embedding dimension explosion"</strong></p>
</li>
<li>Don't naively dump all ColPali vectors into regular PGVector.</li>
<li>
<p><strong>Fix</strong>: Must implement 13.3.3 Binary Quantization. Or use ColPali only for complex "key pages"; ordinary text pages still use BGE/OpenAI Embedding, building hybrid index.</p>
</li>
<li>
<p><strong>Misconception 3: "Use CLIP directly as OCR replacement"</strong></p>
</li>
<li>CLIP knows images contain "text" but can't read long text. If you ask "Who is Party A in the contract?," standard CLIP usually can't answer.</li>
<li><strong>Fix</strong>: For text-dense images without complex layout, OCR + LLM remains cost-effective; ColPali applies to "layout is semantics" scenarios (e.g., complex nested tables).</li>
</ul>
<hr>
<h2 id="chapter-summary_1">Chapter Summary<a class="headerlink" href="#chapter-summary_1" title="Permanent link">¶</a></h2>
<p>Multimodal RAG expands our vision from 1D text to 2D visual space.</p>
<ul>
<li><strong>Architecture</strong>: Use SigLIP for natural images, ColPali for document images.</li>
<li><strong>Code</strong>: Core lies in MaxSim interactive scoring, not simple dot product.</li>
<li><strong>Optimization</strong>: Binary Quantization (BQ) is key technology enabling large-scale multimodal RAG deployment.</li>
</ul>
<p>Mastering this chapter, your RAG system is no longer "blind" but a "versatile expert" that can read charts and analyze reports.</p>
<hr>
<h2 id="further-reading">Further Reading<a class="headerlink" href="#further-reading" title="Permanent link">¶</a></h2>
<ul>
<li><strong>Paper</strong>: <em>ColPali: Efficient Document Retrieval with Vision Language Models</em> (2024).</li>
<li><strong>Tool</strong>: <code>colpali_engine</code> official library; track its native Qdrant/Weaviate support updates.</li>
<li><strong>Advanced</strong>: Learn <strong>Matryoshka Representation Learning (MRL)</strong> for further vector dimension compression.</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer">
        
          
          <a href="../5_1_rag_pipeline/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Chapter 12: RAG Data Pipeline">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Chapter 12: RAG Data Pipeline
              </div>
            </div>
          </a>
        
        
          
          <a href="../../part6/6_1_mini_c4/" class="md-footer__link md-footer__link--next" aria-label="Next: Project 1: Building Mini-C4 Pre-training Set">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Project 1: Building Mini-C4 Pre-training Set
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.sections", "navigation.expand", "navigation.indexes", "navigation.top", "navigation.footer", "toc.follow", "search.suggest", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>