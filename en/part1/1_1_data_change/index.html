<!DOCTYPE html><html lang="en" class="no-js"><head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="大模型数据工程：架构、算法及项目实战">
      
      
        <meta name="author" content="ustc">
      
      
        <link rel="canonical" href="https://datascale-ai.github.io/data_engineering_book/en/part1/1_1_data_change/">
      
      
        <link rel="prev" href="../../">
      
      
        <link rel="next" href="../1_2_data_infra/">
      
      
        
          <link rel="alternate" href="../../../part1/1_1_data_change/" hreflang="zh">
        
          <link rel="alternate" href="./" hreflang="en">
        
          <link rel="alternate" href="../../../ja/part1/1_1_data_change/" hreflang="ja">
        
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.2">
    
    
      
        <title>Chapter 1: Data Revolution in the LLM Era - Data Engineering for Large Models: Architecture, Algorithms &amp; Projects</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"><script src="../../../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="red">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#chapter-1-data-transformation-in-the-era-of-large-language-models-from-data-ops-to-ai-ops" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../" title="Data Engineering for Large Models: Architecture, Algorithms &amp; Projects" class="md-header__button md-logo" aria-label="Data Engineering for Large Models: Architecture, Algorithms &amp; Projects" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Data Engineering for Large Models: Architecture, Algorithms &amp; Projects
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Chapter 1: Data Revolution in the LLM Era
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="red" aria-label="Switch to dark mode" type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"></path></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="red" aria-label="Switch to light mode" type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"></path></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="../../../part1/1_1_data_change/" hreflang="zh" class="md-select__link">
              简体中文
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="./" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="../../../ja/part1/1_1_data_change/" hreflang="ja" class="md-select__link">
              日本語
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/datascale-ai/data_engineering_book/tree/main" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../" title="Data Engineering for Large Models: Architecture, Algorithms &amp; Projects" class="md-nav__button md-logo" aria-label="Data Engineering for Large Models: Architecture, Algorithms &amp; Projects" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    Data Engineering for Large Models: Architecture, Algorithms &amp; Projects
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/datascale-ai/data_engineering_book/tree/main" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Table of Contents
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 1: Infrastructure &amp; Core Concepts
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 1: Infrastructure &amp; Core Concepts
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Chapter 1: Data Revolution in the LLM Era
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 1: Data Revolution in the LLM Era
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#chapter-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Scenario Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-implications-of-scaling-laws-paradigm-shift-from-big-data-to-high-quality-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1 Implications of Scaling Laws: Paradigm Shift from "Big Data" to "High-Quality Data"
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.1 Implications of Scaling Laws: Paradigm Shift from &quot;Big Data&quot; to &quot;High-Quality Data&quot;">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-what-are-scaling-laws" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1.1 What Are Scaling Laws?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#112-the-hidden-variable-of-data-quality" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1.2 The "Hidden Variable" of Data Quality
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#113-quality-vs-quantity-the-extreme-experiment-of-the-phi-series" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1.3 Quality vs. Quantity: The Extreme Experiment of the Phi Series
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#114-the-core-mission-of-data-engineers" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1.4 The Core Mission of Data Engineers
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-full-lifecycle-of-llm-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.2 Full Lifecycle of LLM Data
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.2 Full Lifecycle of LLM Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#121-four-stage-paradigm-pre-train-sft-rlhf-rag" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.2.1 Four-Stage Paradigm: Pre-train → SFT → RLHF → RAG
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#122-the-funnel-model-of-data-flow" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.2.2 The "Funnel Model" of Data Flow
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-challenges-and-opportunities-the-game-of-heterogeneous-multimodal-copyright-compliance-and-compute-cost" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3 Challenges and Opportunities: The Game of Heterogeneous Multimodal, Copyright Compliance, and Compute Cost
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.3 Challenges and Opportunities: The Game of Heterogeneous Multimodal, Copyright Compliance, and Compute Cost">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#131-challenge-one-complexity-of-processing-heterogeneous-multimodal-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3.1 Challenge One: Complexity of Processing Heterogeneous Multimodal Data
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#132-challenge-two-the-gray-zone-of-copyright-compliance" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3.2 Challenge Two: The Gray Zone of Copyright Compliance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#133-challenge-three-the-hidden-killer-of-compute-cost" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3.3 Challenge Three: The "Hidden Killer" of Compute Cost
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#134-opportunity-three-trends-lowering-the-barrier" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3.4 Opportunity: Three Trends Lowering the Barrier
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#14-common-misconceptions-and-pitfall-guide" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.4 Common Misconceptions and Pitfall Guide
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.4 Common Misconceptions and Pitfall Guide">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#misconception-one-more-data-is-better" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception One: "More Data Is Better"
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#misconception-two-process-all-data-once" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception Two: "Process All Data Once"
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#misconception-three-only-focus-on-pre-training-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception Three: "Only Focus on Pre-training Data"
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#misconception-four-open-source-data-is-ready-to-use" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception Four: "Open-Source Data Is Ready to Use"
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#15-chapter-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.5 Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading" class="md-nav__link">
    <span class="md-ellipsis">
      
        Further Reading
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#preview-of-next-chapter" class="md-nav__link">
    <span class="md-ellipsis">
      
        Preview of Next Chapter
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_2_data_infra/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 2: Data Infrastructure Selection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3">
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 2: Text Pre-training Data Engineering
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 2: Text Pre-training Data Engineering
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part2/2_1_data_acquisition/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 3: Data Acquisition
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part2/2_2_cleaning_denoising/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 4: Cleaning &amp; Deduplication
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part2/2_3_tokenization_serialization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 5: Tokenization &amp; Serialization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4">
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 3: Multimodal Data Engineering
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 3: Multimodal Data Engineering
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part3/3_1_image_text_pairs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 6: Image-Text Pair Processing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part3/3_2_recaptioning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 7: Recaptioning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part3/3_3_video_audio/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 8: Video &amp; Audio Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5">
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 4: Alignment &amp; Synthetic Data Engineering
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 4: Alignment &amp; Synthetic Data Engineering
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part4/4_1_sft_data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 9: Instruction Fine-tuning Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part4/4_2_synthetic_data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 10: Synthetic Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part4/4_3_preference_data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 11: Human Preference Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6">
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 5: Application-level Data Engineering
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 5: Application-level Data Engineering
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part5/5_1_rag_pipeline/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 12: RAG Data Pipeline
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part5/5_2_mm_rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 13: Multimodal RAG
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7">
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 6: Capstone Projects
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 6: Capstone Projects
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_1_mini_c4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 1: Building Mini-C4 Pre-training Set
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_2_legal_sft/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 2: Domain Expert SFT
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_3_llava_instruct/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 3: Building LLaVA Multimodal Instruction Set
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_4_synthetic_textbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 4: Synthetic Math/Code Textbook
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_5_mm_rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 5: Multimodal RAG Financial Report Assistant
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#chapter-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Scenario Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-implications-of-scaling-laws-paradigm-shift-from-big-data-to-high-quality-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1 Implications of Scaling Laws: Paradigm Shift from "Big Data" to "High-Quality Data"
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.1 Implications of Scaling Laws: Paradigm Shift from &quot;Big Data&quot; to &quot;High-Quality Data&quot;">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-what-are-scaling-laws" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1.1 What Are Scaling Laws?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#112-the-hidden-variable-of-data-quality" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1.2 The "Hidden Variable" of Data Quality
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#113-quality-vs-quantity-the-extreme-experiment-of-the-phi-series" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1.3 Quality vs. Quantity: The Extreme Experiment of the Phi Series
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#114-the-core-mission-of-data-engineers" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.1.4 The Core Mission of Data Engineers
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-full-lifecycle-of-llm-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.2 Full Lifecycle of LLM Data
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.2 Full Lifecycle of LLM Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#121-four-stage-paradigm-pre-train-sft-rlhf-rag" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.2.1 Four-Stage Paradigm: Pre-train → SFT → RLHF → RAG
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#122-the-funnel-model-of-data-flow" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.2.2 The "Funnel Model" of Data Flow
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-challenges-and-opportunities-the-game-of-heterogeneous-multimodal-copyright-compliance-and-compute-cost" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3 Challenges and Opportunities: The Game of Heterogeneous Multimodal, Copyright Compliance, and Compute Cost
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.3 Challenges and Opportunities: The Game of Heterogeneous Multimodal, Copyright Compliance, and Compute Cost">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#131-challenge-one-complexity-of-processing-heterogeneous-multimodal-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3.1 Challenge One: Complexity of Processing Heterogeneous Multimodal Data
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#132-challenge-two-the-gray-zone-of-copyright-compliance" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3.2 Challenge Two: The Gray Zone of Copyright Compliance
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#133-challenge-three-the-hidden-killer-of-compute-cost" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3.3 Challenge Three: The "Hidden Killer" of Compute Cost
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#134-opportunity-three-trends-lowering-the-barrier" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.3.4 Opportunity: Three Trends Lowering the Barrier
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#14-common-misconceptions-and-pitfall-guide" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.4 Common Misconceptions and Pitfall Guide
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.4 Common Misconceptions and Pitfall Guide">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#misconception-one-more-data-is-better" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception One: "More Data Is Better"
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#misconception-two-process-all-data-once" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception Two: "Process All Data Once"
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#misconception-three-only-focus-on-pre-training-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception Three: "Only Focus on Pre-training Data"
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#misconception-four-open-source-data-is-ready-to-use" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception Four: "Open-Source Data Is Ready to Use"
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#15-chapter-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        1.5 Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading" class="md-nav__link">
    <span class="md-ellipsis">
      
        Further Reading
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#preview-of-next-chapter" class="md-nav__link">
    <span class="md-ellipsis">
      
        Preview of Next Chapter
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="chapter-1-data-transformation-in-the-era-of-large-language-models-from-data-ops-to-ai-ops">Chapter 1: Data Transformation in the Era of Large Language Models (From Data Ops to AI Ops)<a class="headerlink" href="#chapter-1-data-transformation-in-the-era-of-large-language-models-from-data-ops-to-ai-ops" title="Permanent link">¶</a></h1>
<hr>
<h2 id="chapter-summary">Chapter Summary<a class="headerlink" href="#chapter-summary" title="Permanent link">¶</a></h2>
<p>The rise of Large Language Models (LLMs) has reshaped the paradigm of artificial intelligence. However, innovation in model architecture has converged, and what truly determines the upper limit of model capability is <strong>data quality</strong>. This chapter establishes the concept of "data as core asset" from the perspective of Scaling Laws, systematically introduces the full lifecycle of LLM data, and explores practical challenges such as heterogeneous multimodal data, copyright compliance, and compute cost.</p>
<hr>
<h2 id="scenario-introduction">Scenario Introduction<a class="headerlink" href="#scenario-introduction" title="Permanent link">¶</a></h2>
<p>You are the data lead at an AI startup. The team has just spent three months crawling 50TB of Chinese text from the public web and is confidently starting to pre-train a 7B parameter base model.</p>
<p>However, two weeks into training, the loss curve suddenly "flattens" at a certain point, and the model output is filled with ad copy, repetitive SEO junk, and even recites user agreements from certain websites. In the post-mortem meeting, a senior engineer raises a sharp question: "After spending 1 million on compute for training, are we building a language model, or a compressed index of internet garbage?"</p>
<p>This scenario is not fabricated. OpenAI, Google, Meta, and other top labs have already reached consensus: in an era of converging model architectures, data quality is the core variable that determines the intelligence ceiling of models.</p>
<hr>
<h2 id="11-implications-of-scaling-laws-paradigm-shift-from-big-data-to-high-quality-data">1.1 Implications of Scaling Laws: Paradigm Shift from "Big Data" to "High-Quality Data"<a class="headerlink" href="#11-implications-of-scaling-laws-paradigm-shift-from-big-data-to-high-quality-data" title="Permanent link">¶</a></h2>
<h3 id="111-what-are-scaling-laws">1.1.1 What Are Scaling Laws?<a class="headerlink" href="#111-what-are-scaling-laws" title="Permanent link">¶</a></h3>
<p>In 2020, OpenAI published the landmark paper <em>Scaling Laws for Neural Language Models</em>, revealing a simple yet profound regularity: model performance (measured by Loss) follows a power law relationship with three core factors—model parameter count <span class="arithmatex">\(N\)</span>, dataset size <span class="arithmatex">\(D\)</span>, and compute <span class="arithmatex">\(C\)</span>.</p>
<div class="arithmatex">\[
L(N, D, C) \approx \left(\frac{N_c}{N}\right)^{\alpha_N} + \left(\frac{D_c}{D}\right)^{\alpha_D} + \left(\frac{C_c}{C}\right)^{\alpha_C}
\]</div>
<p>Where <span class="arithmatex">\(L\)</span> is the model's cross-entropy loss, <span class="arithmatex">\(N_c, D_c, C_c\)</span> are constants, and <span class="arithmatex">\(\alpha\)</span> are power law exponents. In plain terms: to make a model smarter, you either increase model scale, add more data, or invest more compute. These three factors constrain each other, forming the "impossible triangle" of the LLM era.</p>
<p>This discovery sent shockwaves through academia and industry. Before this, the development of deep learning was more like "alchemy"—researchers relied on intuition and experience to tune model architectures, hoping for accidental breakthroughs. The emergence of Scaling Laws shifted large model training from art to engineering science for the first time, enabling companies to plan resource investment and expected outcomes based on precise mathematical models.</p>
<h3 id="112-the-hidden-variable-of-data-quality">1.1.2 The "Hidden Variable" of Data Quality<a class="headerlink" href="#112-the-hidden-variable-of-data-quality" title="Permanent link">¶</a></h3>
<p>However, the original Scaling Laws had a critical blind spot: it assumed that all data "quality" was uniform. This assumption clearly does not hold in reality. Text quality on the internet varies widely, from carefully written academic papers to comments riddled with typos, and the value difference between data can span orders of magnitude.</p>
<p>In 2022, DeepMind's Chinchilla paper shattered this assumption. The research team conducted a large-scale experiment: under the same compute budget, compare the effects of different model sizes and data volume ratios. The results shocked the industry—Chinchilla (70B parameters), with only one-quarter the parameters of Gopher, surpassed the 280B parameter Gopher on almost all evaluation tasks by using four times the high-quality training data (1.4T tokens).</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Parameters</th>
<th>Training Tokens</th>
<th>Final Performance</th>
</tr>
</thead>
<tbody>
<tr>
<td>Gopher</td>
<td>280B</td>
<td>300B tokens</td>
<td>Baseline</td>
</tr>
<tr>
<td><strong>Chinchilla</strong></td>
<td><strong>70B</strong></td>
<td><strong>1.4T tokens</strong></td>
<td><strong>Outperforms Gopher</strong></td>
</tr>
</tbody>
</table>
<p>This research revealed a long-neglected fact: the industry had previously overfitted on model scale while undervaluing data volume. The Chinchilla paper recommended an "optimal ratio": for each additional parameter, approximately 20 tokens of training data should be allocated. This means training a 7B model theoretically requires about 140B tokens of high-quality corpus—a number far beyond what many teams initially expected.</p>
<h3 id="113-quality-vs-quantity-the-extreme-experiment-of-the-phi-series">1.1.3 Quality vs. Quantity: The Extreme Experiment of the Phi Series<a class="headerlink" href="#113-quality-vs-quantity-the-extreme-experiment-of-the-phi-series" title="Permanent link">¶</a></h3>
<p>If Chinchilla proved that "data volume was underestimated," then Microsoft's Phi series demonstrated an even more radical view: data quality can override the scaling laws.</p>
<p>In 2023, Microsoft Research released the Phi-1 model. This is a "small" model with only 1.3B parameters, trained on merely 7B tokens—a stark contrast to the mainstream approach of hundreds of billions or even trillions of tokens at the time. Yet this seemingly "malnourished" model surpassed competitors with ten times its parameters on code generation tasks.</p>
<p>Phi-1's secret weapon was not massive crawled data, but carefully designed synthetic data with pedagogical value. The researchers used GPT-4 to generate large amounts of structured, step-by-step programming tutorials, from basic syntax to advanced algorithms, forming a complete "artificial textbook." These synthetic data had advantages that real web data could hardly match: no noise, no errors, clear logic, and progressive difficulty. Small models trained on these "artificial textbooks" showed remarkable capability in solving real programming problems.</p>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part1/%E5%9B%BE1_1_%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E5%AF%B9%E6%AF%94.png" data-desc-position="bottom"><img alt="Figure 1-1: Data Quality Comparison" src="../../../images/part1/%E5%9B%BE1_1_%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E5%AF%B9%E6%AF%94.png"></a></p>
<p><em>Figure 1-1: Relationship between Data Quality and Model Performance — Low-quality data (40% noise) after cleansing becomes high-quality data (5% noise)</em></p>
<p>The success of the Phi series sparked heated discussion in the industry about "synthetic data." If carefully designed synthetic data could produce such excellent results, does the traditional "crawl-clean-train" paradigm need to be overturned? We will explore synthetic data methodology and best practices in detail in Chapter 7.</p>
<h3 id="114-the-core-mission-of-data-engineers">1.1.4 The Core Mission of Data Engineers<a class="headerlink" href="#114-the-core-mission-of-data-engineers" title="Permanent link">¶</a></h3>
<p>Synthesizing the above research, we can distill the core mission of data engineers in the LLM era. Traditional wisdom held that "more data is better"; the new paradigm emphasizes that data quality determines the performance ceiling, and noisy data is not only unhelpful but harmful. Past belief was that "model architecture is the core competitive advantage"; today architecture has converged, and data has become the key differentiator. The old view that "cleaning is a minor preprocessing step" is outdated—data cleaning is now seen as the foundation of successful model training. Similarly, the traditional belief that "human annotation is irreplaceable" has been broken; high-quality synthetic data can surpass real data in certain scenarios.</p>
<p>It is important to emphasize that "quality over quantity" should not be misinterpreted as "only quality, no quantity." Scaling Laws still hold—the priority under the same compute budget should be investing in data quality. An extreme example: a model trained on 100 perfect data points can never surpass a model trained on 1T high-quality data points. Quality and quantity are not opposed; they require finding the optimal balance under practical constraints.</p>
<hr>
<h2 id="12-full-lifecycle-of-llm-data">1.2 Full Lifecycle of LLM Data<a class="headerlink" href="#12-full-lifecycle-of-llm-data" title="Permanent link">¶</a></h2>
<p>From "birth" to "deployment," a large language model undergoes multiple training stages, each with distinctly different data requirements. Understanding this full lifecycle is the first step toward becoming a qualified data engineer.</p>
<h3 id="121-four-stage-paradigm-pre-train-sft-rlhf-rag">1.2.1 Four-Stage Paradigm: Pre-train → SFT → RLHF → RAG<a class="headerlink" href="#121-four-stage-paradigm-pre-train-sft-rlhf-rag" title="Permanent link">¶</a></h3>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part1/%E5%9B%BE1_2_LLM%E6%95%B0%E6%8D%AE%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.png" data-desc-position="bottom"><img alt="Figure 1-2: LLM Data Lifecycle" src="../../../images/part1/%E5%9B%BE1_2_LLM%E6%95%B0%E6%8D%AE%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.png"></a></p>
<p><em>Figure 1-2: LLM Training Data Pipeline — From TB-level pre-training to KB-level RAG, data volume decreases while quality requirements increase</em></p>
<p><strong>Pre-training</strong> is the starting point of a large model's life. At this stage, the model learns the essence of language from massive amounts of unlabeled text—grammatical structure, commonsense knowledge, and how the world works. Pre-training data scale is typically at the TB level, containing trillions of tokens, with sources from web pages, books, code, academic papers, and other text types. The core challenges at this stage are deduplication, denoising, quality filtering, and diversity balance. Typical pre-training datasets include Common Crawl, The Pile, and RefinedWeb.</p>
<p><strong>Supervised Fine-Tuning (SFT)</strong> is the critical period when the model learns to "follow instructions." Although pre-trained models possess strong language understanding capability, they do not know how to interact effectively with humans. The SFT stage uses paired instruction-response data to teach the model to understand user intent and provide helpful responses. Data scale at this stage drops to GB level, containing hundreds of thousands to millions of carefully constructed dialogue samples. Key challenges include ensuring instruction diversity, response quality, and format standardization. Alpaca, ShareGPT, and OpenAssistant are commonly used datasets for this stage.</p>
<p><strong>Reinforcement Learning from Human Feedback (RLHF/DPO)</strong> aims to make model output more "aligned" with human preferences. Alignment means making the model safer (not producing harmful content), more helpful (actually solving user problems), and more honest (not fabricating facts). This stage uses preference comparison data where human annotators choose the better of two candidate responses. Data scale further shrinks from hundreds of thousands to tens of thousands of samples, but annotation quality requirements are extremely high. Inter-Annotator Agreement, accuracy of preference signals, and coverage of sample distribution are all factors that must be carefully controlled.</p>
<p><strong>Retrieval-Augmented Generation (RAG)</strong> addresses model knowledge updates and hallucination. No matter how thorough pre-training is, a model's knowledge has a cutoff date and cannot completely avoid "sounding authoritative while talking nonsense." RAG injects external information such as enterprise knowledge bases and latest documents into the generation process by letting the model "consult external sources." Data sources at this stage are typically enterprise-private, including PDF documents, database records, web content, and other structured or semi-structured data. Key challenges include document parsing, semantic chunking, vectorization, and retrieval accuracy optimization.</p>
<h3 id="122-the-funnel-model-of-data-flow">1.2.2 The "Funnel Model" of Data Flow<a class="headerlink" href="#122-the-funnel-model-of-data-flow" title="Permanent link">¶</a></h3>
<p>Another perspective on understanding the data lifecycle is the "funnel model." From raw web data to final high-quality corpus usable for training, data volume undergoes dramatic reduction.</p>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part1/%E5%9B%BE1_3_%E6%95%B0%E6%8D%AE%E6%BC%8F%E6%96%97%E6%A8%A1%E5%9E%8B.png" data-desc-position="bottom"><img alt="Figure 1-3: Data Funnel Model" src="../../../images/part1/%E5%9B%BE1_3_%E6%95%B0%E6%8D%AE%E6%BC%8F%E6%96%97%E6%A8%A1%E5%9E%8B.png"></a></p>
<p><em>Figure 1-3: Data filtration funnel — From 100PB raw data to 10GB SFT data, retention rate only 0.00001%</em></p>
<p>For a typical pre-training data processing workflow: assume we obtain 100PB of raw web data from Common Crawl. After URL deduplication and exact-content deduplication, data volume may drop to 30PB (30% retention). Next, language identification and quality filtering—removing non-target languages, pornographic/violent content, extremely short text, garbled text—further reduces data to 5PB (5% retention). Then finer quality assessment using perplexity, repetition rate, information density, and other metrics yields final pre-training corpus of perhaps only 1PB (1% retention). And if SFT data needs to be extracted or constructed from this, the final output may be only 10GB—relative to raw data, retention rate as low as one hundred-thousandth.</p>
<p>In practical engineering, understanding this ratio is crucial. It directly affects planning of crawl scale, storage cost budgeting, and processing pipeline design. Many teams underestimated this "attrition rate" at project start, leading to insufficient data reserves and mid-project rework.</p>
<hr>
<h2 id="13-challenges-and-opportunities-the-game-of-heterogeneous-multimodal-copyright-compliance-and-compute-cost">1.3 Challenges and Opportunities: The Game of Heterogeneous Multimodal, Copyright Compliance, and Compute Cost<a class="headerlink" href="#13-challenges-and-opportunities-the-game-of-heterogeneous-multimodal-copyright-compliance-and-compute-cost" title="Permanent link">¶</a></h2>
<h3 id="131-challenge-one-complexity-of-processing-heterogeneous-multimodal-data">1.3.1 Challenge One: Complexity of Processing Heterogeneous Multimodal Data<a class="headerlink" href="#131-challenge-one-complexity-of-processing-heterogeneous-multimodal-data" title="Permanent link">¶</a></h3>
<p>With the emergence of multimodal models like GPT-4V, Gemini, and Sora, data engineering complexity has increased exponentially. In the pure text era, all data was UTF-8 encoded strings; processing toolchains were mature and standardized. In the multimodal era, data formats have exploded: images have JPEG, PNG, WebP; video has MP4, AVI, MKV; audio has WAV, MP3, FLAC; documents have PDF, Word, HTML. Each format has its own parsing methods and quality assessment standards.</p>
<table>
<thead>
<tr>
<th>Dimension</th>
<th>Pure Text Era</th>
<th>Multimodal Era</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Data Format</strong></td>
<td>Unified UTF-8 text</td>
<td>Multiple formats: images, video, audio, documents, web pages</td>
</tr>
<tr>
<td><strong>Storage Requirements</strong></td>
<td>TB level</td>
<td>PB level (images/video dominate)</td>
</tr>
<tr>
<td><strong>Alignment Difficulty</strong></td>
<td>None (pure text needs no alignment)</td>
<td>Very high (image-text alignment, audio-video sync, cross-modal semantic consistency)</td>
</tr>
<tr>
<td><strong>Cleaning Toolchain</strong></td>
<td>Mature (FastText, KenLM)</td>
<td>Fragmented (each modality has independent toolchain)</td>
</tr>
<tr>
<td><strong>Quality Assessment</strong></td>
<td>Perplexity, deduplication rate</td>
<td>Aesthetic score, CLIP-Score, OCR accuracy, ASR error rate, etc.</td>
</tr>
</tbody>
</table>
<p>Even more challenging is the cross-modal alignment problem. An image paired with a caption—how to ensure the text accurately describes the image content? How do voice and visuals in a video stay precisely synchronized? These alignment problems did not exist in the pure text era but are core challenges in multimodal data engineering.</p>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part1/%E5%9B%BE1_4_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%84%E7%90%86%E5%A4%8D%E6%9D%82%E5%BA%A6.png" data-desc-position="bottom"><img alt="Figure 1-4: Multimodal Processing Complexity" src="../../../images/part1/%E5%9B%BE1_4_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%84%E7%90%86%E5%A4%8D%E6%9D%82%E5%BA%A6.png"></a></p>
<p><em>Figure 1-4: Multimodal Data Processing Complexity — Line thickness indicates processing difficulty, video (5/5) and PDF (4/5) are most complex</em></p>
<p>From an engineering practice perspective, multimodal data processing requires modular design—each modality processed independently before cross-modal alignment. At the same time, priority should be given to unified data format standards such as WebDataset, TFDS, etc., to reduce downstream processing complexity. Establishing modality-aware quality assessment systems is also critical: images need aesthetic scores and CLIP similarity, speech needs ASR accuracy and speaker separation quality, PDFs need OCR accuracy and layout analysis precision.</p>
<h3 id="132-challenge-two-the-gray-zone-of-copyright-compliance">1.3.2 Challenge Two: The Gray Zone of Copyright Compliance<a class="headerlink" href="#132-challenge-two-the-gray-zone-of-copyright-compliance" title="Permanent link">¶</a></h3>
<p>Copyright issues with large model training data have evolved from technical discussion to legal battlefield. In 2023, Getty Images sued Stability AI, alleging unauthorized use of millions of copyrighted images to train Stable Diffusion. In 2024, <em>The New York Times</em> sued OpenAI and Microsoft, alleging GPT models infringed copyright. Regulatory agencies in multiple countries have begun requiring AI companies to disclose training data sources.</p>
<p>The outcomes of these lawsuits will profoundly affect the development direction of the AI industry, but for data engineers, waiting for matters to be resolved is clearly not wise. Current compliance strategies can proceed from several aspects: First, source traceability—record complete source metadata for each training data point, including URL, crawl time, original copyright declaration, etc.; Second, license filtering—prioritize data with explicit permission for AI training use, such as CC0, CC-BY and other open license content; Third, respect robots.txt protocol, honoring website owners' crawler restriction declarations; Fourth, data desensitization—anonymize or delete content involving personal privacy.</p>
<p>It is worth noting that "Fair Use" boundaries in AI training scenarios remain unclear, and applicable legal standards vary by country. Therefore, it is recommended to reserve copyright filtering interfaces in the data pipeline so that data processing strategies can be quickly adjusted once the legal environment is clarified.</p>
<h3 id="133-challenge-three-the-hidden-killer-of-compute-cost">1.3.3 Challenge Three: The "Hidden Killer" of Compute Cost<a class="headerlink" href="#133-challenge-three-the-hidden-killer-of-compute-cost" title="Permanent link">¶</a></h3>
<p>Compute cost for data processing is often severely underestimated. Many teams only calculate GPU training time when budgeting model training costs, but neglect that data preprocessing may consume equal or more resources.</p>
<p>Consider a practical scenario: processing 10TB of raw web data. Assume each data point requires five steps on average: HTML parsing, text extraction, language identification, quality scoring, deduplication check. Each step takes 100 milliseconds per item (already quite fast). Total processing time would be approximately: 10TB ÷ 10KB/item × 0.5 sec/item ≈ 1.5 million GPU hours. At cloud provider pricing, this could mean hundreds of thousands of dollars—comparable to model training costs itself.</p>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Training Data Volume</th>
<th>Training Cost (A100 hours)</th>
<th>Model Performance</th>
</tr>
</thead>
<tbody>
<tr>
<td>No deduplication, train directly</td>
<td>10T Token</td>
<td>10,000 hours</td>
<td>Baseline (includes "repeater" issues from repetition)</td>
</tr>
<tr>
<td>Train after deduplication</td>
<td>7T Token</td>
<td>7,000 hours</td>
<td>Better than baseline (repeated data reduces learning efficiency)</td>
</tr>
<tr>
<td><strong>Net benefit</strong></td>
<td>-</td>
<td><strong>Save 3,000 hours + better model</strong></td>
<td>-</td>
</tr>
</tbody>
</table>
<p>However, from another perspective, the return on investment of data engineering can be extremely high. The table above shows a simplified case: by investing resources in data deduplication, not only 30% of training cost is saved, but better model performance is achieved. This is the "leverage effect" of data engineering—at current compute prices (A100 ~$2/hour), 1 hour of data processing work that can eliminate 10 hours of ineffective training yields 20x ROI.</p>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part1/%E5%9B%BE1_5_%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E4%B8%8E%E8%AE%AD%E7%BB%83%E6%95%88%E7%8E%87.png" data-desc-position="bottom"><img alt="Figure 1-5: Data Quality and Training Efficiency" src="../../../images/part1/%E5%9B%BE1_5_%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E4%B8%8E%E8%AE%AD%E7%BB%83%E6%95%88%E7%8E%87.png"></a></p>
<p><em>Figure 1-5: Relationship between Data Quality and Training Efficiency — Green curve (curated data) most efficient, 30-70% quality range has maximum ROI</em></p>
<h3 id="134-opportunity-three-trends-lowering-the-barrier">1.3.4 Opportunity: Three Trends Lowering the Barrier<a class="headerlink" href="#134-opportunity-three-trends-lowering-the-barrier" title="Permanent link">¶</a></h3>
<p>Despite challenges, for data engineers, now is the golden time to enter. Three major trends are significantly lowering the barrier to large model data engineering.</p>
<p>The first trend is the emergence of open-source high-quality datasets. Unlike early closed commercial data, recent years have seen many high-quality open-source pre-training datasets. HuggingFace's FineWeb provides carefully cleaned 15T token English web data. RedPajama open-sourced the complete reproduction of LLaMA training data. DCLM provides domain-optimized datasets. These open-source datasets greatly reduce the cost for small and medium teams to build pre-training corpora, making resources that were previously only accessible to large companies within reach.</p>
<p>The second trend is the maturation of AI-native data tools. Traditional big data tools (like Hadoop, Spark) are mature but not designed for AI training scenarios. In recent years, a batch of tools designed for LLM data engineering have matured. Alibaba's Data-Juicer provides modular data processing pipelines with dozens of out-of-the-box cleaning operators. Dolma is an Allen AI-developed large-scale text processing toolkit for pre-training data optimization. These tools enable data engineers to stand on the shoulders of giants without building from scratch.</p>
<p>The third trend is the mainstreaming of synthetic data. As mentioned, Microsoft Phi series success demonstrated the enormous potential of synthetic data. Today, using powerful models like GPT-4, Claude to generate training data has become industry standard. This "strong-leading-weak" strategy makes high-quality data acquisition no longer completely dependent on human annotation, greatly accelerating data preparation efficiency. However, synthetic data also brings new challenges: How to avoid model collapse? How to ensure data diversity? These questions will be explored in detail in subsequent chapters.</p>
<hr>
<h2 id="14-common-misconceptions-and-pitfall-guide">1.4 Common Misconceptions and Pitfall Guide<a class="headerlink" href="#14-common-misconceptions-and-pitfall-guide" title="Permanent link">¶</a></h2>
<p>Before entering specific technical practice, it is necessary to clarify several common misconceptions. These misconceptions can lead to resource waste at best, and project failure at worst.</p>
<h3 id="misconception-one-more-data-is-better">Misconception One: "More Data Is Better"<a class="headerlink" href="#misconception-one-more-data-is-better" title="Permanent link">¶</a></h3>
<p>This is the most common and most harmful misconception. Many teams' first reaction when starting a project is to "crawl as much data as possible." However, as mentioned, raw data retention rate is typically only 5-20%. Blindly pursuing data volume means 80%+ of crawl, storage, and initial processing costs are wasted. Worse, if subsequent quality filtering is not strict enough and low-quality data mixed into the training set, it may negatively impact model performance.</p>
<p>The correct approach: first validate the entire processing pipeline's effectiveness with small-scale data, confirm quality standards and filtering strategy, then proceed with large-scale data collection. "Quality first, quantity second" should be a fundamental principle of data engineering.</p>
<h3 id="misconception-two-process-all-data-once">Misconception Two: "Process All Data Once"<a class="headerlink" href="#misconception-two-process-all-data-once" title="Permanent link">¶</a></h3>
<p>Data processing is an iterative process, not a one-time task. Model training will expose data issues (e.g., excess samples of certain types leading to bias), evaluation results will guide data filtering strategy (e.g., need to augment data in certain domains), legal compliance requirements may change (e.g., need to remove data from certain sources).</p>
<p>Therefore, data processing pipelines must be designed for reproducible execution, incremental updates, and version rollback. Chapter 2 will detail how to use tools like DVC, LakeFS for data version control.</p>
<h3 id="misconception-three-only-focus-on-pre-training-data">Misconception Three: "Only Focus on Pre-training Data"<a class="headerlink" href="#misconception-three-only-focus-on-pre-training-data" title="Permanent link">¶</a></h3>
<p>Pre-training data is indeed the foundation of LLMs, but neglecting data from subsequent stages is equally dangerous. A base model well pre-trained on large corpus may produce mediocre dialogue models if SFT data quality is poor. Similarly, if RLHF preference data has inconsistent annotations, the model may exhibit unstable behavior.</p>
<p>Full lifecycle data quality management is equally important. Pre-training, SFT, RLHF, and RAG data should each have their own quality standards and evaluation systems.</p>
<h3 id="misconception-four-open-source-data-is-ready-to-use">Misconception Four: "Open-Source Data Is Ready to Use"<a class="headerlink" href="#misconception-four-open-source-data-is-ready-to-use" title="Permanent link">¶</a></h3>
<p>Open-source datasets greatly lower the entry barrier, but using open-source data directly without secondary review is dangerous. Open-source datasets may have: outdated data (crawled earlier, missing latest knowledge), bias (uneven data distribution), noise (some samples not meeting quality standards), copyright risk (unclear license).</p>
<p>The correct approach is to treat open-source data as "raw material" rather than "finished product." Secondary filtering, augmentation, and balancing based on your own task requirements are needed to maximize the value of open-source data.</p>
<hr>
<h2 id="15-chapter-summary">1.5 Chapter Summary<a class="headerlink" href="#15-chapter-summary" title="Permanent link">¶</a></h2>
<p>This chapter systematically discussed the core concepts of data engineering in the LLM era from the perspective of Scaling Laws. We first explored the paradigm shift of "quality over quantity," from Chinchilla's optimal ratio to the extreme experiment of the Phi series, demonstrating the decisive role of high-quality data in model performance.</p>
<p>We then introduced the four stages of the LLM data lifecycle: pre-training, SFT, RLHF, and RAG. Each stage has distinctly different data requirements, from TB-level unlabeled text to tens of thousands of preference comparison data points—data volume decreases while quality requirements increase. Understanding this "funnel model" is the foundation for planning data resources.</p>
<p>In the challenges and opportunities section, we analyzed three practical issues: multimodal complexity, copyright compliance, and compute cost, while also seeing opportunities from three trends: open-source datasets, AI-native tools, and synthetic data.</p>
<p>Finally, by clarifying four common misconceptions, we established the correct data engineering mindset for readers: quality before quantity, iterative rather than one-time, full-cycle management, and secondary processing of open-source data.</p>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part1/%E5%9B%BE1_6_%E7%9F%A5%E8%AF%86%E7%BB%93%E6%9E%84%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.png" data-desc-position="bottom"><img alt="Figure 1-6: Knowledge Structure Mind Map" src="../../../images/part1/%E5%9B%BE1_6_%E7%9F%A5%E8%AF%86%E7%BB%93%E6%9E%84%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.png"></a></p>
<p><em>Figure 1-6: Chapter 1 Knowledge Structure — Covering four major themes: Scaling Laws, Data Lifecycle, Challenges and Opportunities</em></p>
<hr>
<h2 id="further-reading">Further Reading<a class="headerlink" href="#further-reading" title="Permanent link">¶</a></h2>
<p><strong>Core Papers</strong></p>
<p><em>Scaling Laws for Neural Language Models</em> by Kaplan et al. (2020) is the foundational work for understanding large model resource allocation. This OpenAI paper first systematically revealed the power law relationship between model scale, data volume, and compute, providing theoretical guidance for subsequent large model development.</p>
<p><em>Training Compute-Optimal Large Language Models</em> (the Chinchilla paper) by Hoffmann et al. (2022) from DeepMind pointed out the industry's widespread "over-parameterization" problem and provided compute-optimal model-data ratio recommendations.</p>
<p><em>Textbooks Are All You Need</em> by Gunasekar et al. (2023) from Microsoft Research is the pioneering work of the Phi series, proving that high-quality synthetic data can enable small models to match large model performance.</p>
<p><strong>Open-Source Datasets</strong></p>
<p>FineWeb released by Penedo et al. is HuggingFace's open-source large-scale high-quality English web dataset, containing approximately 15T tokens, suitable as a base corpus for pre-training. RedPajama released by Together AI is the open-source reproduction of LLaMA training data, valuable for teams wanting to reproduce the LLaMA training process.</p>
<hr>
<h2 id="preview-of-next-chapter">Preview of Next Chapter<a class="headerlink" href="#preview-of-next-chapter" title="Permanent link">¶</a></h2>
<p>In the next chapter <em>Data Infrastructure Selection</em>, we will move from conceptual to engineering level. You will learn how to choose appropriate storage solutions (S3 vs MinIO), compute frameworks (Spark vs Ray), data formats (Parquet vs JSONL vs WebDataset), and version control tools (DVC vs LakeFS).</p>
<p>Take this question into the next chapter: With limited resources, how do you design a data infrastructure that can support current needs while scaling smoothly?</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer">
        
          
          <a href="../../" class="md-footer__link md-footer__link--prev" aria-label="Previous: Table of Contents">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Table of Contents
              </div>
            </div>
          </a>
        
        
          
          <a href="../1_2_data_infra/" class="md-footer__link md-footer__link--next" aria-label="Next: Chapter 2: Data Infrastructure Selection">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Chapter 2: Data Infrastructure Selection
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.sections", "navigation.expand", "navigation.indexes", "navigation.top", "navigation.footer", "toc.follow", "search.suggest", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>