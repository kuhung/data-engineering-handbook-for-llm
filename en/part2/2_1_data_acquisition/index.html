<!DOCTYPE html><html lang="en" class="no-js"><head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="大模型数据工程：架构、算法及项目实战">
      
      
        <meta name="author" content="ustc">
      
      
        <link rel="canonical" href="https://datascale-ai.github.io/data_engineering_book/en/part2/2_1_data_acquisition/">
      
      
        <link rel="prev" href="../../part1/1_2_data_infra/">
      
      
        <link rel="next" href="../2_2_cleaning_denoising/">
      
      
        
          <link rel="alternate" href="../../../part2/2_1_data_acquisition/" hreflang="zh">
        
          <link rel="alternate" href="./" hreflang="en">
        
          <link rel="alternate" href="../../../ja/part2/2_1_data_acquisition/" hreflang="ja">
        
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.2">
    
    
      
        <title>Chapter 3: Data Acquisition - Data Engineering for Large Models: Architecture, Algorithms &amp; Projects</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"><script src="../../../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="red">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#chapter-3-data-acquisition-commoncrawl-parsing-and-high-concurrency-crawling" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../" title="Data Engineering for Large Models: Architecture, Algorithms &amp; Projects" class="md-header__button md-logo" aria-label="Data Engineering for Large Models: Architecture, Algorithms &amp; Projects" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Data Engineering for Large Models: Architecture, Algorithms &amp; Projects
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Chapter 3: Data Acquisition
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="red" aria-label="Switch to dark mode" type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"></path></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="red" aria-label="Switch to light mode" type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"></path></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="../../../part2/2_1_data_acquisition/" hreflang="zh" class="md-select__link">
              简体中文
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="./" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="../../../ja/part2/2_1_data_acquisition/" hreflang="ja" class="md-select__link">
              日本語
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/datascale-ai/data_engineering_book/tree/main" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../" title="Data Engineering for Large Models: Architecture, Algorithms &amp; Projects" class="md-nav__button md-logo" aria-label="Data Engineering for Large Models: Architecture, Algorithms &amp; Projects" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    Data Engineering for Large Models: Architecture, Algorithms &amp; Projects
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/datascale-ai/data_engineering_book/tree/main" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Table of Contents
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2">
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 1: Infrastructure &amp; Core Concepts
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 1: Infrastructure &amp; Core Concepts
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part1/1_1_data_change/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 1: Data Revolution in the LLM Era
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part1/1_2_data_infra/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 2: Data Infrastructure Selection
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 2: Text Pre-training Data Engineering
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 2: Text Pre-training Data Engineering
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Chapter 3: Data Acquisition
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 3: Data Acquisition
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#chapter-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Scenario Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#31-deconstruction-of-open-source-datasets" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1 Deconstruction of Open-Source Datasets
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.1 Deconstruction of Open-Source Datasets">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#311-common-crawl-a-snapshot-of-the-internet" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1.1 Common Crawl: A Snapshot of the Internet
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#312-refinedweb-high-quality-english-corpus" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1.2 RefinedWeb: High-Quality English Corpus
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#313-the-pile-diversified-data-mixture" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1.3 The Pile: Diversified Data Mixture
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#314-overview-of-chinese-datasets" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1.4 Overview of Chinese Datasets
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#32-high-performance-web-parsing" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2 High-Performance Web Parsing
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.2 High-Performance Web Parsing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#321-challenges-of-web-parsing" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2.1 Challenges of Web Parsing
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#322-trafilatura-industrial-grade-parsing-library" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2.2 Trafilatura: Industrial-Grade Parsing Library
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#323-comparison-of-other-parsing-tools" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2.3 Comparison of Other Parsing Tools
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#324-distributed-parsing-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2.4 Distributed Parsing Architecture
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#33-specialized-data-acquisition" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3 Specialized Data Acquisition
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.3 Specialized Data Acquisition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#331-code-data-github-and-the-stack" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3.1 Code Data: GitHub and The Stack
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#332-academic-papers-arxiv-and-s2orc" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3.2 Academic Papers: ArXiv and S2ORC
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#333-book-data-copyright-and-alternative-solutions" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3.3 Book Data: Copyright and Alternative Solutions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#334-multilingual-data-balancing" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3.4 Multilingual Data Balancing
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#34-engineering-practices-for-data-acquisition" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.4 Engineering Practices for Data Acquisition
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.4 Engineering Practices for Data Acquisition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#341-crawler-architecture-design" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.4.1 Crawler Architecture Design
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#342-incremental-update-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.4.2 Incremental Update Strategy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#343-quality-monitoring-and-feedback" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.4.3 Quality Monitoring and Feedback
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#35-common-pitfalls-and-best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.5 Common Pitfalls and Best Practices
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#36-chapter-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.6 Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading" class="md-nav__link">
    <span class="md-ellipsis">
      
        Further Reading
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-chapter-preview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Next Chapter Preview
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2_2_cleaning_denoising/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 4: Cleaning &amp; Deduplication
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2_3_tokenization_serialization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 5: Tokenization &amp; Serialization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4">
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 3: Multimodal Data Engineering
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 3: Multimodal Data Engineering
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part3/3_1_image_text_pairs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 6: Image-Text Pair Processing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part3/3_2_recaptioning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 7: Recaptioning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part3/3_3_video_audio/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 8: Video &amp; Audio Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5">
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 4: Alignment &amp; Synthetic Data Engineering
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 4: Alignment &amp; Synthetic Data Engineering
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part4/4_1_sft_data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 9: Instruction Fine-tuning Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part4/4_2_synthetic_data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 10: Synthetic Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part4/4_3_preference_data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 11: Human Preference Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6">
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 5: Application-level Data Engineering
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 5: Application-level Data Engineering
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part5/5_1_rag_pipeline/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 12: RAG Data Pipeline
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part5/5_2_mm_rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter 13: Multimodal RAG
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7">
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Part 6: Capstone Projects
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Part 6: Capstone Projects
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_1_mini_c4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 1: Building Mini-C4 Pre-training Set
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_2_legal_sft/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 2: Domain Expert SFT
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_3_llava_instruct/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 3: Building LLaVA Multimodal Instruction Set
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_4_synthetic_textbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 4: Synthetic Math/Code Textbook
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../part6/6_5_mm_rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Project 5: Multimodal RAG Financial Report Assistant
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#chapter-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scenario-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Scenario Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#31-deconstruction-of-open-source-datasets" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1 Deconstruction of Open-Source Datasets
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.1 Deconstruction of Open-Source Datasets">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#311-common-crawl-a-snapshot-of-the-internet" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1.1 Common Crawl: A Snapshot of the Internet
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#312-refinedweb-high-quality-english-corpus" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1.2 RefinedWeb: High-Quality English Corpus
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#313-the-pile-diversified-data-mixture" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1.3 The Pile: Diversified Data Mixture
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#314-overview-of-chinese-datasets" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1.4 Overview of Chinese Datasets
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#32-high-performance-web-parsing" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2 High-Performance Web Parsing
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.2 High-Performance Web Parsing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#321-challenges-of-web-parsing" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2.1 Challenges of Web Parsing
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#322-trafilatura-industrial-grade-parsing-library" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2.2 Trafilatura: Industrial-Grade Parsing Library
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#323-comparison-of-other-parsing-tools" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2.3 Comparison of Other Parsing Tools
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#324-distributed-parsing-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2.4 Distributed Parsing Architecture
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#33-specialized-data-acquisition" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3 Specialized Data Acquisition
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.3 Specialized Data Acquisition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#331-code-data-github-and-the-stack" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3.1 Code Data: GitHub and The Stack
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#332-academic-papers-arxiv-and-s2orc" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3.2 Academic Papers: ArXiv and S2ORC
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#333-book-data-copyright-and-alternative-solutions" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3.3 Book Data: Copyright and Alternative Solutions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#334-multilingual-data-balancing" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3.4 Multilingual Data Balancing
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#34-engineering-practices-for-data-acquisition" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.4 Engineering Practices for Data Acquisition
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.4 Engineering Practices for Data Acquisition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#341-crawler-architecture-design" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.4.1 Crawler Architecture Design
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#342-incremental-update-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.4.2 Incremental Update Strategy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#343-quality-monitoring-and-feedback" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.4.3 Quality Monitoring and Feedback
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#35-common-pitfalls-and-best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.5 Common Pitfalls and Best Practices
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#36-chapter-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.6 Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading" class="md-nav__link">
    <span class="md-ellipsis">
      
        Further Reading
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#next-chapter-preview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Next Chapter Preview
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="chapter-3-data-acquisition-commoncrawl-parsing-and-high-concurrency-crawling">Chapter 3: Data Acquisition (CommonCrawl Parsing and High-Concurrency Crawling)<a class="headerlink" href="#chapter-3-data-acquisition-commoncrawl-parsing-and-high-concurrency-crawling" title="Permanent link">¶</a></h1>
<hr>
<h2 id="chapter-summary">Chapter Summary<a class="headerlink" href="#chapter-summary" title="Permanent link">¶</a></h2>
<p>Pre-training data is the "fuel" of large models, and its quality and scale directly determine the model's foundational capabilities. This chapter delves into pre-training data acquisition strategies, from deconstructing and using open-source datasets like Common Crawl, to designing and implementing high-performance web crawler systems, and to acquiring specialized data such as code, papers, and books. After mastering this content, readers will possess the ability to build TB-level pre-training corpora.</p>
<hr>
<h2 id="scenario-introduction">Scenario Introduction<a class="headerlink" href="#scenario-introduction" title="Permanent link">¶</a></h2>
<p>Your team has decided to train a 7B parameter Chinese base model. According to Chinchilla's optimal ratio, this requires approximately 140B tokens of high-quality Chinese corpus—translating to about 280TB of raw text. Where can you find this much data? Directly crawling from the web is clearly impractical; a small team cannot crawl the entire Chinese internet in a short time.</p>
<p>At this point, someone suggests using Common Crawl—an open-source project that crawls billions of web pages each month, with cumulative data exceeding PB scale. It sounds like a perfect solution, but when you actually download one month's data, you discover that the raw WARC files are completely unusable: filled with HTML tags, JavaScript code, navigation bars, and ads—the truly valuable body content may be less than 10%.</p>
<p>How do you extract usable "golden corpus" for training from this "data swamp"? This is the core problem this chapter aims to solve.</p>
<hr>
<h2 id="31-deconstruction-of-open-source-datasets">3.1 Deconstruction of Open-Source Datasets<a class="headerlink" href="#31-deconstruction-of-open-source-datasets" title="Permanent link">¶</a></h2>
<p>Before starting to crawl data yourself, you should first fully leverage existing open-source datasets. These datasets have been carefully processed by the community and can significantly reduce the time and cost of preparing pre-training data. Understanding their composition and processing methods is also an important reference for designing your own data pipeline.</p>
<h3 id="311-common-crawl-a-snapshot-of-the-internet">3.1.1 Common Crawl: A Snapshot of the Internet<a class="headerlink" href="#311-common-crawl-a-snapshot-of-the-internet" title="Permanent link">¶</a></h3>
<p>Common Crawl is a non-profit organization that has been continuously crawling internet web pages since 2008 and provides them free of charge for research and commercial use. It is currently the upstream source for the vast majority of large-scale pre-training datasets—whether GPT series, LLaMA, or various Chinese large models, they all use Common Crawl data to varying degrees.</p>
<p>Common Crawl data is organized in "crawl batches," releasing a new batch each month, with each batch containing billions of web pages. The data is provided in three formats: WARC (Web ARChive) files contain raw HTTP responses, including response headers and complete HTML content, making it the most original and complete format; WAT files are metadata-extracted versions of WARC, containing structured information such as URLs, response headers, and link relationships; WET files are plain text extracted versions that have removed HTML tags, preserving only body text.</p>
<table>
<thead>
<tr>
<th>Format</th>
<th>Content</th>
<th>Monthly Data Volume</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td>WARC</td>
<td>Raw HTTP Response + HTML</td>
<td>~80TB compressed</td>
<td>Need complete content or custom parsing</td>
</tr>
<tr>
<td>WAT</td>
<td>Structured metadata</td>
<td>~3TB compressed</td>
<td>URL analysis, link graph research</td>
</tr>
<tr>
<td>WET</td>
<td>Plain text extraction</td>
<td>~15TB compressed</td>
<td>Quick text acquisition, preliminary experiments</td>
</tr>
</tbody>
</table>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part2/%E5%9B%BE3_1_CommonCrawl%E6%95%B0%E6%8D%AE%E6%B5%81%E6%B0%B4%E7%BA%BF.png" data-desc-position="bottom"><img alt="Figure 3-1: Common Crawl Data Pipeline" src="../../../images/part2/%E5%9B%BE3_1_CommonCrawl%E6%95%B0%E6%8D%AE%E6%B5%81%E6%B0%B4%E7%BA%BF.png"></a></p>
<p><em>Figure 3-1: Common Crawl Data Pipeline — Complete processing flow from internet crawling to clean corpus</em></p>
<p>For pre-training data engineering, WARC and WET are the two most commonly used formats. WET files seem convenient because text has already been extracted, but in reality Common Crawl's default text extraction quality is poor, retaining large amounts of noise (such as navigation bars, footers, JavaScript text). Therefore, professional data processing pipelines typically start from WARC files and use higher-quality parsers (such as Trafilatura) to re-extract the body content.</p>
<p>Several key points need attention when using Common Crawl data. First is version selection: each monthly crawl batch varies slightly in quality, and it is generally recommended to use more recent versions (such as batches from after 2023), as Common Crawl continuously improves its crawling strategies. Second is language filtering: Common Crawl is predominantly English web pages, with non-English content like Chinese and Japanese accounting for relatively low proportions (typically less than 10%), requiring additional language identification steps for screening. Finally is legal compliance: although Common Crawl is open data, the web page content it crawls may involve copyright issues and needs to be evaluated according to local laws when using.</p>
<h3 id="312-refinedweb-high-quality-english-corpus">3.1.2 RefinedWeb: High-Quality English Corpus<a class="headerlink" href="#312-refinedweb-high-quality-english-corpus" title="Permanent link">¶</a></h3>
<p>RefinedWeb is a high-quality English pre-training dataset released by the Falcon model team (TII Lab of UAE), containing approximately 5T tokens. Unlike directly using Common Crawl, RefinedWeb has undergone strict cleaning and deduplication processing and is considered one of the highest quality publicly available English pre-training corpora.</p>
<p>RefinedWeb's processing pipeline has strong reference value. Its core steps include: URL filtering (removing adult websites, spam sites, etc.), text extraction (using Trafilatura for high-quality body extraction), language identification (using FastText to retain English content), quality filtering (removing low-quality documents based on heuristic rules), and fuzzy deduplication (using MinHash LSH for approximate deduplication at large scale).</p>
<p>The RefinedWeb paper details the implementation and effectiveness evaluation of each step, making it an excellent textbook for learning pre-training data processing. It's worth noting that although RefinedWeb has publicly released a subset of the dataset (~600B tokens), the complete version remains exclusive to the Falcon model.</p>
<h3 id="313-the-pile-diversified-data-mixture">3.1.3 The Pile: Diversified Data Mixture<a class="headerlink" href="#313-the-pile-diversified-data-mixture" title="Permanent link">¶</a></h3>
<p>The Pile is an open-source pre-training dataset released by EleutherAI, approximately 800GB in size (uncompressed), containing about 300B tokens. Unlike RefinedWeb's focus on web data, The Pile's design philosophy is diversification—it mixes data from 22 different sources, covering web pages, books, code, papers, legal documents, and other domains.</p>
<p>The Pile's data source composition reflects the importance of pre-training data diversity. Among them, Pile-CC is a cleaned Common Crawl subset, accounting for approximately 50%; PubMed Central provides biomedical papers; ArXiv provides scientific preprints; GitHub provides open-source code; Books3 provides book text; StackExchange provides technical Q&amp;A; Wikipedia provides encyclopedic knowledge. This multi-source mixing strategy has been proven to improve model performance across various downstream tasks, with later models like LLaMA and Mistral borrowing similar approaches in their data recipes.</p>
<p>However, The Pile faces legal controversies. Its Books3 subset contains large amounts of copyrighted books and has triggered multiple lawsuits. When using The Pile, it is recommended to evaluate based on your own legal risk tolerance, or selectively exclude controversial subsets.</p>
<h3 id="314-overview-of-chinese-datasets">3.1.4 Overview of Chinese Datasets<a class="headerlink" href="#314-overview-of-chinese-datasets" title="Permanent link">¶</a></h3>
<p>For training Chinese large models, available open-source datasets are relatively scarce, though there has been improvement in recent years.</p>
<p>WuDaoCorpora is a large-scale Chinese corpus released by BAAI, containing approximately 3TB of Chinese text, covering encyclopedias, news, forums, Q&amp;A, and other sources. Data must be obtained through application, and usage must comply with relevant agreements. ChineseCrawl is a Chinese Common Crawl subset extraction, with multiple community versions available. CLUECorpus is Chinese corpus released by the CLUE benchmark team, approximately 100GB in size, suitable for small to medium-scale experiments.</p>
<p>Compared to the richness of English datasets, Chinese pre-training data remains a "seller's market." This means Chinese large model teams often need to acquire and process Chinese data themselves from Common Crawl or other sources, and cannot rely entirely on existing open-source datasets.</p>
<hr>
<h2 id="32-high-performance-web-parsing">3.2 High-Performance Web Parsing<a class="headerlink" href="#32-high-performance-web-parsing" title="Permanent link">¶</a></h2>
<p>After obtaining raw HTML from Common Crawl or your own crawler, the next critical step is extracting body text from it. This seems simple but is actually one of the most critical steps in the entire data pipeline—parsing quality directly determines the quality of the final corpus.</p>
<h3 id="321-challenges-of-web-parsing">3.2.1 Challenges of Web Parsing<a class="headerlink" href="#321-challenges-of-web-parsing" title="Permanent link">¶</a></h3>
<p>Modern web pages are far more complex than they appear on the surface. A typical web page may contain: HTML structural tags, CSS style definitions, JavaScript code (including inline and external references), navigation bars and footers, ads and promotional content, comment sections and user-generated content, page sidebars and recommended content. What we need is only the "body"—the main content section of the page.</p>
<p>Traditional parsing methods (such as simply removing all HTML tags) work poorly because they cannot distinguish between body content and noise. More advanced methods need to understand the semantic structure of web pages and identify which parts are truly valuable content.</p>
<h3 id="322-trafilatura-industrial-grade-parsing-library">3.2.2 Trafilatura: Industrial-Grade Parsing Library<a class="headerlink" href="#322-trafilatura-industrial-grade-parsing-library" title="Permanent link">¶</a></h3>
<p>Trafilatura is currently the most recommended web body extraction library, adopted by mainstream datasets like RefinedWeb and Dolma. Its core advantages lie in: finely-tuned extraction algorithms with excellent performance on multiple evaluation datasets; good multilingual support, especially for Asian languages like Chinese and Japanese; rich configuration options that can adjust extraction strategies according to needs; and reasonable performance suitable for large-scale data processing.</p>
<p>The basic workflow for using Trafilatura is as follows:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">trafilatura</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="c1"># Extract body content from HTML</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="k">def</span><span class="w"> </span><span class="nf">extract_content</span><span class="p">(</span><span class="n">html</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="w">    </span><span class="sd">"""</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">    Extract body content from HTML</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="sd">        html: Raw HTML string</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="sd">        url: Optional URL for resolving relative links</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="sd">        Dictionary containing body content and metadata</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="sd">    """</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="c1"># Core extraction</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">result</span> <span class="o">=</span> <span class="n">trafilatura</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>        <span class="n">html</span><span class="p">,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>        <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>        <span class="n">include_comments</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>    <span class="c1"># Exclude comment section</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span class="n">include_tables</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>       <span class="c1"># Preserve table content</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>        <span class="n">no_fallback</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>         <span class="c1"># Allow fallback algorithms</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>        <span class="n">favor_precision</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>      <span class="c1"># Prioritize precision</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        <span class="n">output_format</span><span class="o">=</span><span class="s1">'txt'</span>        <span class="c1"># Output plain text</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="p">)</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>    <span class="c1"># Extract metadata</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>    <span class="n">metadata</span> <span class="o">=</span> <span class="n">trafilatura</span><span class="o">.</span><span class="n">extract_metadata</span><span class="p">(</span><span class="n">html</span><span class="p">)</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>    <span class="k">return</span> <span class="p">{</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>        <span class="s1">'text'</span><span class="p">:</span> <span class="n">result</span><span class="p">,</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>        <span class="s1">'title'</span><span class="p">:</span> <span class="n">metadata</span><span class="o">.</span><span class="n">title</span> <span class="k">if</span> <span class="n">metadata</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>        <span class="s1">'author'</span><span class="p">:</span> <span class="n">metadata</span><span class="o">.</span><span class="n">author</span> <span class="k">if</span> <span class="n">metadata</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>        <span class="s1">'date'</span><span class="p">:</span> <span class="n">metadata</span><span class="o">.</span><span class="n">date</span> <span class="k">if</span> <span class="n">metadata</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>        <span class="s1">'url'</span><span class="p">:</span> <span class="n">url</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>    <span class="p">}</span>
</code></pre></div>
<p>Trafilatura provides rich configuration options, with different parameter combinations suitable for different scenarios. <code>include_comments</code> controls whether to preserve page comment section content—can be set to True for forum-type websites, usually set to False for news websites. <code>include_tables</code> controls whether to preserve tables—should be set to True for data-type pages (such as Wikipedia). <code>favor_precision</code> and <code>favor_recall</code> are a pair of trade-off parameters; the former prioritizes ensuring extraction accuracy (better to miss than include errors), the latter prioritizes ensuring extraction completeness (better to have noise than be incomplete). For pre-training data, typically choose <code>favor_precision=True</code>, as noisy data harms model training.</p>
<h3 id="323-comparison-of-other-parsing-tools">3.2.3 Comparison of Other Parsing Tools<a class="headerlink" href="#323-comparison-of-other-parsing-tools" title="Permanent link">¶</a></h3>
<p>Besides Trafilatura, there are several commonly used web parsing tools, each with their own characteristics.</p>
<p><strong>Readability</strong> was originally developed by Mozilla for Firefox's reading mode. Its algorithm is relatively simple and fast, but performance on complex pages is average. The Python ecosystem has ported versions like readability-lxml.</p>
<p><strong>Newspaper3k</strong> is specifically optimized for news websites and can effectively extract article titles, body text, publication dates, authors, and other information. However, it performs poorly on non-news sites, and the project is not actively maintained.</p>
<p><strong>Justext</strong> is a library focused on "boilerplate removal," with algorithms based on link density and text density of text blocks. It is commonly cited in academic research but has less engineering practicality than Trafilatura.</p>
<table>
<thead>
<tr>
<th>Tool</th>
<th>Advantages</th>
<th>Disadvantages</th>
<th>Recommended Scenarios</th>
</tr>
</thead>
<tbody>
<tr>
<td>Trafilatura</td>
<td>Best overall performance, good multilingual support</td>
<td>Medium speed</td>
<td>General scenarios, first choice</td>
</tr>
<tr>
<td>Readability</td>
<td>Fast, simple algorithm</td>
<td>Poor on complex pages</td>
<td>Rapid prototyping</td>
</tr>
<tr>
<td>Newspaper3k</td>
<td>Good for news sites</td>
<td>Weak generalization</td>
<td>News corpus specialty</td>
</tr>
<tr>
<td>Justext</td>
<td>Academically well-validated</td>
<td>Less engineering adaptation</td>
<td>Research scenarios</td>
</tr>
</tbody>
</table>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part2/%E5%9B%BE3_2_%E8%A7%A3%E6%9E%90%E5%99%A8%E8%B4%A8%E9%87%8F%E5%AF%B9%E6%AF%94.png" data-desc-position="bottom"><img alt="Figure 3-2: Parser Quality Comparison" src="../../../images/part2/%E5%9B%BE3_2_%E8%A7%A3%E6%9E%90%E5%99%A8%E8%B4%A8%E9%87%8F%E5%AF%B9%E6%AF%94.png"></a></p>
<p><em>Figure 3-2: Web Parser Quality Comparison — Trafilatura leads in F1 score, making it the preferred tool for LLM data processing</em></p>
<p>In actual projects, a common strategy is to use Trafilatura as the primary parser, and when extraction results are empty or too short, fall back to Readability for attempts. This "primary-backup" strategy can improve overall extraction success rate.</p>
<h3 id="324-distributed-parsing-architecture">3.2.4 Distributed Parsing Architecture<a class="headerlink" href="#324-distributed-parsing-architecture" title="Permanent link">¶</a></h3>
<p>Single-machine processing capacity is limited; facing TB-level WARC files requires building distributed parsing systems. Here's an example of distributed parsing based on Ray Data:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">trafilatura</span>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">warcio.archiveiterator</span><span class="w"> </span><span class="kn">import</span> <span class="n">ArchiveIterator</span>
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="kn">import</span><span class="w"> </span><span class="nn">gzip</span>
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a><span class="k">def</span><span class="w"> </span><span class="nf">parse_warc_record</span><span class="p">(</span><span class="n">record</span><span class="p">):</span>
<a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a><span class="w">    </span><span class="sd">"""Parse single WARC record"""</span>
<a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>    <span class="k">if</span> <span class="n">record</span><span class="o">.</span><span class="n">rec_type</span> <span class="o">!=</span> <span class="s1">'response'</span><span class="p">:</span>
<a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>        <span class="k">return</span> <span class="kc">None</span>
<a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>
<a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>    <span class="n">url</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">rec_headers</span><span class="o">.</span><span class="n">get_header</span><span class="p">(</span><span class="s1">'WARC-Target-URI'</span><span class="p">)</span>
<a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>    <span class="n">content_type</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">http_headers</span><span class="o">.</span><span class="n">get_header</span><span class="p">(</span><span class="s1">'Content-Type'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
<a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>
<a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>    <span class="c1"># Only process HTML pages</span>
<a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>    <span class="k">if</span> <span class="s1">'text/html'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">content_type</span><span class="p">:</span>
<a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>        <span class="k">return</span> <span class="kc">None</span>
<a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>
<a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>    <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a>        <span class="n">html</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">content_stream</span><span class="p">()</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s1">'ignore'</span><span class="p">)</span>
<a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a>        <span class="n">text</span> <span class="o">=</span> <span class="n">trafilatura</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">favor_precision</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a>
<a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a>        <span class="k">if</span> <span class="n">text</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">200</span><span class="p">:</span>  <span class="c1"># Filter overly short content</span>
<a id="__codelineno-1-25" name="__codelineno-1-25" href="#__codelineno-1-25"></a>            <span class="k">return</span> <span class="p">{</span>
<a id="__codelineno-1-26" name="__codelineno-1-26" href="#__codelineno-1-26"></a>                <span class="s1">'url'</span><span class="p">:</span> <span class="n">url</span><span class="p">,</span>
<a id="__codelineno-1-27" name="__codelineno-1-27" href="#__codelineno-1-27"></a>                <span class="s1">'text'</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
<a id="__codelineno-1-28" name="__codelineno-1-28" href="#__codelineno-1-28"></a>                <span class="s1">'length'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<a id="__codelineno-1-29" name="__codelineno-1-29" href="#__codelineno-1-29"></a>            <span class="p">}</span>
<a id="__codelineno-1-30" name="__codelineno-1-30" href="#__codelineno-1-30"></a>    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<a id="__codelineno-1-31" name="__codelineno-1-31" href="#__codelineno-1-31"></a>        <span class="k">return</span> <span class="kc">None</span>
<a id="__codelineno-1-32" name="__codelineno-1-32" href="#__codelineno-1-32"></a>
<a id="__codelineno-1-33" name="__codelineno-1-33" href="#__codelineno-1-33"></a>    <span class="k">return</span> <span class="kc">None</span>
<a id="__codelineno-1-34" name="__codelineno-1-34" href="#__codelineno-1-34"></a>
<a id="__codelineno-1-35" name="__codelineno-1-35" href="#__codelineno-1-35"></a><span class="k">def</span><span class="w"> </span><span class="nf">process_warc_file</span><span class="p">(</span><span class="n">warc_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<a id="__codelineno-1-36" name="__codelineno-1-36" href="#__codelineno-1-36"></a><span class="w">    </span><span class="sd">"""Process single WARC file"""</span>
<a id="__codelineno-1-37" name="__codelineno-1-37" href="#__codelineno-1-37"></a>    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-1-38" name="__codelineno-1-38" href="#__codelineno-1-38"></a>
<a id="__codelineno-1-39" name="__codelineno-1-39" href="#__codelineno-1-39"></a>    <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">warc_path</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<a id="__codelineno-1-40" name="__codelineno-1-40" href="#__codelineno-1-40"></a>        <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">ArchiveIterator</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
<a id="__codelineno-1-41" name="__codelineno-1-41" href="#__codelineno-1-41"></a>            <span class="n">result</span> <span class="o">=</span> <span class="n">parse_warc_record</span><span class="p">(</span><span class="n">record</span><span class="p">)</span>
<a id="__codelineno-1-42" name="__codelineno-1-42" href="#__codelineno-1-42"></a>            <span class="k">if</span> <span class="n">result</span><span class="p">:</span>
<a id="__codelineno-1-43" name="__codelineno-1-43" href="#__codelineno-1-43"></a>                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<a id="__codelineno-1-44" name="__codelineno-1-44" href="#__codelineno-1-44"></a>
<a id="__codelineno-1-45" name="__codelineno-1-45" href="#__codelineno-1-45"></a>    <span class="k">return</span> <span class="n">results</span>
<a id="__codelineno-1-46" name="__codelineno-1-46" href="#__codelineno-1-46"></a>
<a id="__codelineno-1-47" name="__codelineno-1-47" href="#__codelineno-1-47"></a><span class="c1"># Get all WARC file paths</span>
<a id="__codelineno-1-48" name="__codelineno-1-48" href="#__codelineno-1-48"></a><span class="n">warc_files</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>  <span class="c1"># S3 or local path list</span>
<a id="__codelineno-1-49" name="__codelineno-1-49" href="#__codelineno-1-49"></a>
<a id="__codelineno-1-50" name="__codelineno-1-50" href="#__codelineno-1-50"></a><span class="c1"># Distributed parallel processing</span>
<a id="__codelineno-1-51" name="__codelineno-1-51" href="#__codelineno-1-51"></a><span class="n">ds</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_items</span><span class="p">(</span><span class="n">warc_files</span><span class="p">)</span>
<a id="__codelineno-1-52" name="__codelineno-1-52" href="#__codelineno-1-52"></a><span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">flat_map</span><span class="p">(</span><span class="n">process_warc_file</span><span class="p">)</span>
<a id="__codelineno-1-53" name="__codelineno-1-53" href="#__codelineno-1-53"></a>
<a id="__codelineno-1-54" name="__codelineno-1-54" href="#__codelineno-1-54"></a><span class="c1"># Save results</span>
<a id="__codelineno-1-55" name="__codelineno-1-55" href="#__codelineno-1-55"></a><span class="n">ds</span><span class="o">.</span><span class="n">write_parquet</span><span class="p">(</span><span class="s2">"s3://bucket/parsed_data/"</span><span class="p">)</span>
</code></pre></div>
<p>Key design points of this architecture include: using Ray Data's <code>flat_map</code> operator to achieve file-level parallelism; performing error handling inside the parsing function to avoid single data failures affecting batch processing; early filtering through conditions like <code>len(text) &gt; 200</code> to reduce downstream processing volume; outputting in Parquet format for convenient subsequent deduplication and filtering steps.</p>
<hr>
<h2 id="33-specialized-data-acquisition">3.3 Specialized Data Acquisition<a class="headerlink" href="#33-specialized-data-acquisition" title="Permanent link">¶</a></h2>
<p>Besides general web data, pre-training corpora typically also need to include specialized domain data such as code, academic papers, and books. These "specialized data" have unique challenges and techniques for acquisition and processing.</p>
<h3 id="331-code-data-github-and-the-stack">3.3.1 Code Data: GitHub and The Stack<a class="headerlink" href="#331-code-data-github-and-the-stack" title="Permanent link">¶</a></h3>
<p>Code capability is one of the core competencies of modern large models, and acquiring high-quality code data is the foundation for achieving this capability. Currently, the most important source of code data is GitHub.</p>
<p>Obtaining code directly from the GitHub API is feasible but inefficient and has request limits. A more common approach is to use public data mirrors of GitHub. Google BigQuery hosts complete snapshots of GitHub public repositories and allows querying and exporting using SQL. Software Heritage is an organization dedicated to preserving humanity's software heritage and maintains a complete archive of GitHub.</p>
<p>For large-scale code data needs, the most convenient choice is to use The Stack dataset released by the BigCode project. This dataset crawls code in over 300 programming languages from GitHub, with a total size of about 3TB. The Stack's processing pipeline includes: license-based filtering (retaining only code allowed by open-source licenses), deduplication (removing duplicate files and code snippets), and PII cleaning (removing sensitive information).</p>
<p>Special attention is needed when using code data:</p>
<p><strong>License compliance</strong> is the primary concern. Different open-source licenses have different restrictions on code usage. The Stack dataset provides license tags and can be filtered according to needs. For commercial model training, it is recommended to only use code with permissive licenses like MIT and Apache 2.0.</p>
<p><strong>Code quality varies greatly</strong>. GitHub contains both high-quality projects like the Linux kernel and large amounts of student assignments and personal experimental code. Common quality filtering strategies include: filtering by repository star count (retaining repositories with star &gt; 10), filtering by file length (removing overly short or long files), and detecting syntax errors based on AST parsing.</p>
<p><strong>Example of processing code data</strong>:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">ast</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="k">def</span><span class="w"> </span><span class="nf">is_valid_python</span><span class="p">(</span><span class="n">code</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="w">    </span><span class="sd">"""Check if Python code is syntactically correct"""</span>
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>    <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>        <span class="n">ast</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">code</span><span class="p">)</span>
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>        <span class="k">return</span> <span class="kc">True</span>
<a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>    <span class="k">except</span> <span class="ne">SyntaxError</span><span class="p">:</span>
<a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>        <span class="k">return</span> <span class="kc">False</span>
<a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>
<a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a><span class="k">def</span><span class="w"> </span><span class="nf">extract_functions</span><span class="p">(</span><span class="n">code</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a><span class="w">    </span><span class="sd">"""Extract function definitions from code"""</span>
<a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>    <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>        <span class="n">tree</span> <span class="o">=</span> <span class="n">ast</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">code</span><span class="p">)</span>
<a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a>        <span class="n">functions</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a>        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">ast</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">tree</span><span class="p">):</span>
<a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">ast</span><span class="o">.</span><span class="n">FunctionDef</span><span class="p">):</span>
<a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a>                <span class="n">functions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ast</span><span class="o">.</span><span class="n">unparse</span><span class="p">(</span><span class="n">node</span><span class="p">))</span>
<a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a>        <span class="k">return</span> <span class="n">functions</span>
<a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a>    <span class="k">except</span><span class="p">:</span>
<a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a>        <span class="k">return</span> <span class="p">[]</span>
<a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a>
<a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a><span class="k">def</span><span class="w"> </span><span class="nf">filter_code_quality</span><span class="p">(</span><span class="n">code</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
<a id="__codelineno-2-25" name="__codelineno-2-25" href="#__codelineno-2-25"></a>                        <span class="n">min_lines</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> 
<a id="__codelineno-2-26" name="__codelineno-2-26" href="#__codelineno-2-26"></a>                        <span class="n">max_lines</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
<a id="__codelineno-2-27" name="__codelineno-2-27" href="#__codelineno-2-27"></a>                        <span class="n">require_docstring</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<a id="__codelineno-2-28" name="__codelineno-2-28" href="#__codelineno-2-28"></a><span class="w">    </span><span class="sd">"""Code quality filtering"""</span>
<a id="__codelineno-2-29" name="__codelineno-2-29" href="#__codelineno-2-29"></a>    <span class="n">lines</span> <span class="o">=</span> <span class="n">code</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<a id="__codelineno-2-30" name="__codelineno-2-30" href="#__codelineno-2-30"></a>
<a id="__codelineno-2-31" name="__codelineno-2-31" href="#__codelineno-2-31"></a>    <span class="c1"># Length filtering</span>
<a id="__codelineno-2-32" name="__codelineno-2-32" href="#__codelineno-2-32"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">min_lines</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_lines</span><span class="p">):</span>
<a id="__codelineno-2-33" name="__codelineno-2-33" href="#__codelineno-2-33"></a>        <span class="k">return</span> <span class="kc">None</span>
<a id="__codelineno-2-34" name="__codelineno-2-34" href="#__codelineno-2-34"></a>
<a id="__codelineno-2-35" name="__codelineno-2-35" href="#__codelineno-2-35"></a>    <span class="c1"># Syntax check</span>
<a id="__codelineno-2-36" name="__codelineno-2-36" href="#__codelineno-2-36"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_valid_python</span><span class="p">(</span><span class="n">code</span><span class="p">):</span>
<a id="__codelineno-2-37" name="__codelineno-2-37" href="#__codelineno-2-37"></a>        <span class="k">return</span> <span class="kc">None</span>
<a id="__codelineno-2-38" name="__codelineno-2-38" href="#__codelineno-2-38"></a>
<a id="__codelineno-2-39" name="__codelineno-2-39" href="#__codelineno-2-39"></a>    <span class="c1"># Docstring check (optional)</span>
<a id="__codelineno-2-40" name="__codelineno-2-40" href="#__codelineno-2-40"></a>    <span class="k">if</span> <span class="n">require_docstring</span> <span class="ow">and</span> <span class="s1">'"""'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">code</span> <span class="ow">and</span> <span class="s2">"'''"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">code</span><span class="p">:</span>
<a id="__codelineno-2-41" name="__codelineno-2-41" href="#__codelineno-2-41"></a>        <span class="k">return</span> <span class="kc">None</span>
<a id="__codelineno-2-42" name="__codelineno-2-42" href="#__codelineno-2-42"></a>
<a id="__codelineno-2-43" name="__codelineno-2-43" href="#__codelineno-2-43"></a>    <span class="k">return</span> <span class="n">code</span>
</code></pre></div>
<h3 id="332-academic-papers-arxiv-and-s2orc">3.3.2 Academic Papers: ArXiv and S2ORC<a class="headerlink" href="#332-academic-papers-arxiv-and-s2orc" title="Permanent link">¶</a></h3>
<p>Academic papers are an important source of high-quality knowledge and significantly help improve models' reasoning abilities and professional knowledge levels.</p>
<p><strong>ArXiv</strong> is the most important open-access preprint platform, covering academic papers in fields like physics, mathematics, computer science, and biology. ArXiv provides bulk download services, with LaTeX source files and PDFs accessible through its S3 bucket. LaTeX source files are a more ideal data source because they preserve the structural information of papers (sections, formulas, citations, etc.) and are in plain text format, easy to process.</p>
<p>The main challenge in processing ArXiv LaTeX data lies in the complexity of LaTeX syntax. A paper may contain dozens of <code>.tex</code> files, using custom macros and styles. A practical simplification strategy is: extract only the main file (usually <code>main.tex</code> or files related to the paper title), use regular expressions to remove figure-table and complex formula environments, and preserve body text and simple mathematical expressions.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">tarfile</span>
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="k">def</span><span class="w"> </span><span class="nf">extract_arxiv_text</span><span class="p">(</span><span class="n">latex_content</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a><span class="w">    </span><span class="sd">"""Extract plain text from LaTeX"""</span>
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>    <span class="n">text</span> <span class="o">=</span> <span class="n">latex_content</span>
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>    <span class="c1"># Remove comments</span>
<a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'%.*$'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">MULTILINE</span><span class="p">)</span>
<a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>
<a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>    <span class="c1"># Remove figure environments</span>
<a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'</span><span class="se">\\</span><span class="s1">begin\{figure\}.*?</span><span class="se">\\</span><span class="s1">end\{figure\}'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>
<a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'</span><span class="se">\\</span><span class="s1">begin\{table\}.*?</span><span class="se">\\</span><span class="s1">end\{table\}'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>
<a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>
<a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>    <span class="c1"># Simplify citations</span>
<a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'</span><span class="se">\\</span><span class="s1">cite\{[^}]+\}'</span><span class="p">,</span> <span class="s1">'[CITATION]'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
<a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'</span><span class="se">\\</span><span class="s1">ref\{[^}]+\}'</span><span class="p">,</span> <span class="s1">'[REF]'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
<a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>
<a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a>    <span class="c1"># Remove common commands but preserve arguments</span>
<a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>    <span class="n">commands_to_strip</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'textbf'</span><span class="p">,</span> <span class="s1">'textit'</span><span class="p">,</span> <span class="s1">'emph'</span><span class="p">,</span> <span class="s1">'section'</span><span class="p">,</span> <span class="s1">'subsection'</span><span class="p">,</span> 
<a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a>                         <span class="s1">'paragraph'</span><span class="p">,</span> <span class="s1">'title'</span><span class="p">,</span> <span class="s1">'author'</span><span class="p">]</span>
<a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a>    <span class="k">for</span> <span class="n">cmd</span> <span class="ow">in</span> <span class="n">commands_to_strip</span><span class="p">:</span>
<a id="__codelineno-3-24" name="__codelineno-3-24" href="#__codelineno-3-24"></a>        <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">rf</span><span class="s1">'</span><span class="se">\\</span><span class="si">{</span><span class="n">cmd</span><span class="si">}</span><span class="s1">\</span><span class="se">{{</span><span class="s1">([^</span><span class="se">}}</span><span class="s1">]+)\</span><span class="se">}}</span><span class="s1">'</span><span class="p">,</span> <span class="sa">r</span><span class="s1">'\1'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
<a id="__codelineno-3-25" name="__codelineno-3-25" href="#__codelineno-3-25"></a>
<a id="__codelineno-3-26" name="__codelineno-3-26" href="#__codelineno-3-26"></a>    <span class="c1"># Remove other commands</span>
<a id="__codelineno-3-27" name="__codelineno-3-27" href="#__codelineno-3-27"></a>    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'</span><span class="se">\\</span><span class="s1">[a-zA-Z]+(\[[^\]]*\])?\{[^}]*\}'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
<a id="__codelineno-3-28" name="__codelineno-3-28" href="#__codelineno-3-28"></a>    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'</span><span class="se">\\</span><span class="s1">[a-zA-Z]+'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
<a id="__codelineno-3-29" name="__codelineno-3-29" href="#__codelineno-3-29"></a>
<a id="__codelineno-3-30" name="__codelineno-3-30" href="#__codelineno-3-30"></a>    <span class="c1"># Clean whitespace</span>
<a id="__codelineno-3-31" name="__codelineno-3-31" href="#__codelineno-3-31"></a>    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'\n\s*\n'</span><span class="p">,</span> <span class="s1">'</span><span class="se">\n\n</span><span class="s1">'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
<a id="__codelineno-3-32" name="__codelineno-3-32" href="#__codelineno-3-32"></a>    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">' +'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
<a id="__codelineno-3-33" name="__codelineno-3-33" href="#__codelineno-3-33"></a>
<a id="__codelineno-3-34" name="__codelineno-3-34" href="#__codelineno-3-34"></a>    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</code></pre></div>
<p><strong>Semantic Scholar Open Research Corpus (S2ORC)</strong> is a large-scale academic paper dataset released by Allen AI, containing metadata for over 80M papers and full text for approximately 8M papers. Compared to ArXiv, S2ORC covers broader fields, including multiple sources like PubMed and ACL Anthology. S2ORC's full text has been processed into structured JSON format, eliminating the hassle of LaTeX/PDF parsing, making it a convenient choice for quickly acquiring paper data.</p>
<h3 id="333-book-data-copyright-and-alternative-solutions">3.3.3 Book Data: Copyright and Alternative Solutions<a class="headerlink" href="#333-book-data-copyright-and-alternative-solutions" title="Permanent link">¶</a></h3>
<p>Books are an important source of high-quality long texts and are valuable for training models' long-range comprehension abilities and knowledge depth. However, the copyright issues of book data are particularly sensitive.</p>
<p><strong>Books3 in The Pile</strong> contains approximately 200,000 books from sources like Bibliotik. This dataset has triggered multiple copyright lawsuits, with several companies being sued for using this dataset to train models. In the current legal environment, directly using Books3 poses significant legal risks.</p>
<p><strong>Compliant alternatives</strong> include:</p>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part2/%E5%9B%BE3_3_%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90%E6%B7%B7%E5%90%88.png" data-desc-position="bottom"><img alt="Figure 3-3: Pre-training Data Source Mixture" src="../../../images/part2/%E5%9B%BE3_3_%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90%E6%B7%B7%E5%90%88.png"></a></p>
<p><em>Figure 3-3: Pre-training Data Source Mixture — Multi-source mixing strategy can improve models' comprehensive capabilities</em></p>
<p>Project Gutenberg is a volunteer project providing copyright-expired classic books. Primarily English books published before 1928, about 70,000 volumes. High data quality, but from a distant era with insufficient coverage of modern language.</p>
<p>Internet Archive's Open Library provides borrowable e-books. Usage must comply with its borrowing agreements; large-scale batch acquisition may violate terms of service.</p>
<p>Wikisource provides public domain literary works, covering multiple languages including large amounts of classical Chinese texts.</p>
<p>Academic textbooks and Open Educational Resources (OER) like OpenStax provide high-quality textbook content suitable for building education-focused pre-training data.</p>
<p>For commercial model training, the safest strategy is to only use book data that has been explicitly authorized or is in the public domain. Although this limits data scale, it can avoid potential legal risks.</p>
<h3 id="334-multilingual-data-balancing">3.3.4 Multilingual Data Balancing<a class="headerlink" href="#334-multilingual-data-balancing" title="Permanent link">¶</a></h3>
<p>When training multilingual models, data availability varies greatly across languages. English data is most abundant, major languages like Chinese, Japanese, and German are second, while high-quality data for minor languages is extremely scarce.</p>
<p>Data imbalance leads to uneven model capabilities. If simply mixing according to original proportions, English will dominate overwhelmingly and minor languages will barely be learned. Common solution strategies include:</p>
<p><strong>Upsampling minor languages</strong> is the most direct method, increasing the weight of minor language data through repeated sampling. However, excessive repetition may lead to overfitting.</p>
<p><strong>Temperature sampling</strong> is a more refined method. Set a temperature parameter T, where the sampling probability for language L is <span class="arithmatex">\(p_L \propto n_L^{1/T}\)</span>, where <span class="arithmatex">\(n_L\)</span> is the original data volume for that language. When T=1, it degenerates to original proportions; as T→∞, it approaches uniform distribution. LLaMA 2 used temperature sampling around T=0.3.</p>
<p>The <strong>quality over quantity</strong> approach is also worth considering. For minor languages with scarce data, translation or synthesis methods can be used to augment data, but attention must be paid to translation quality and unnatural translation issues.</p>
<hr>
<h2 id="34-engineering-practices-for-data-acquisition">3.4 Engineering Practices for Data Acquisition<a class="headerlink" href="#34-engineering-practices-for-data-acquisition" title="Permanent link">¶</a></h2>
<p>Connecting all the above steps to build a complete data acquisition pipeline requires considering many engineering details.</p>
<h3 id="341-crawler-architecture-design">3.4.1 Crawler Architecture Design<a class="headerlink" href="#341-crawler-architecture-design" title="Permanent link">¶</a></h3>
<p>For scenarios requiring independent data crawling (rather than using Common Crawl), distributed crawler architecture design is crucial. A typical architecture includes the following components:</p>
<p><strong>URL Manager</strong> is responsible for maintaining queues of URLs to be crawled, recording the status of crawled URLs, and handling URL deduplication and priority sorting. Common implementation methods include Redis queues combined with Bloom Filter deduplication.</p>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part2/%E5%9B%BE3_4_%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB%E6%9E%B6%E6%9E%84.png" data-desc-position="bottom"><img alt="Figure 3-4: Distributed Crawler Architecture" src="../../../images/part2/%E5%9B%BE3_4_%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB%E6%9E%B6%E6%9E%84.png"></a></p>
<p><em>Figure 3-4: Distributed Web Crawling System Architecture — Collaboration between URL Manager, downloader cluster, parser, and storage layer</em></p>
<p><strong>Downloader Cluster</strong> is responsible for actual HTTP requests. Key considerations include: concurrency control (avoiding excessive pressure on target websites), proxy pool management (dealing with anti-crawler mechanisms), retry strategies (handling network fluctuations and temporary failures), and robots.txt compliance (respecting website crawler rules).</p>
<p><strong>Parser</strong> is responsible for extracting body content and metadata from downloaded HTML, which was discussed in detail in the previous section.</p>
<p><strong>Storage Layer</strong> is responsible for persisting crawl results. For large-scale crawling, it is recommended to write directly to object storage (S3/MinIO) in WARC or Parquet format.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="c1"># Simplified crawler example</span>
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">asyncio</span>
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">aiohttp</span>
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">urllib.parse</span><span class="w"> </span><span class="kn">import</span> <span class="n">urlparse</span>
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="kn">import</span><span class="w"> </span><span class="nn">trafilatura</span>
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>
<a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="k">class</span><span class="w"> </span><span class="nc">SimpleCrawler</span><span class="p">:</span>
<a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_concurrent</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
<a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_concurrent</span> <span class="o">=</span> <span class="n">max_concurrent</span>
<a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">semaphore</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">Semaphore</span><span class="p">(</span><span class="n">max_concurrent</span><span class="p">)</span>
<a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">visited</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>
<a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">fetch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">session</span><span class="p">:</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a><span class="w">        </span><span class="sd">"""Asynchronously fetch and parse single URL"""</span>
<a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>        <span class="k">if</span> <span class="n">url</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">visited</span><span class="p">:</span>
<a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>            <span class="k">return</span> <span class="kc">None</span>
<a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">visited</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>        <span class="n">ntigravity</span><span class="p">:</span> <span class="n">Reset</span> <span class="n">onboarding</span>
<a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a>        <span class="k">async</span> <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">semaphore</span><span class="p">:</span>
<a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>            <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a>                <span class="k">async</span> <span class="k">with</span> <span class="n">session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
<a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>                    <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">:</span>
<a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a>                        <span class="k">return</span> <span class="kc">None</span>
<a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>                    <span class="n">html</span> <span class="o">=</span> <span class="k">await</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">()</span>
<a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a>                    <span class="n">text</span> <span class="o">=</span> <span class="n">trafilatura</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">)</span>
<a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a>                    <span class="k">return</span> <span class="p">{</span><span class="s1">'url'</span><span class="p">:</span> <span class="n">url</span><span class="p">,</span> <span class="s1">'text'</span><span class="p">:</span> <span class="n">text</span><span class="p">}</span> <span class="k">if</span> <span class="n">text</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a>            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
<a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a>                <span class="k">return</span> <span class="kc">None</span>
<a id="__codelineno-4-29" name="__codelineno-4-29" href="#__codelineno-4-29"></a>
<a id="__codelineno-4-30" name="__codelineno-4-30" href="#__codelineno-4-30"></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">crawl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">urls</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<a id="__codelineno-4-31" name="__codelineno-4-31" href="#__codelineno-4-31"></a><span class="w">        </span><span class="sd">"""Batch crawl URL list"""</span>
<a id="__codelineno-4-32" name="__codelineno-4-32" href="#__codelineno-4-32"></a>        <span class="k">async</span> <span class="k">with</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">ClientSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
<a id="__codelineno-4-33" name="__codelineno-4-33" href="#__codelineno-4-33"></a>            <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">fetch</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">url</span><span class="p">)</span> <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">]</span>
<a id="__codelineno-4-34" name="__codelineno-4-34" href="#__codelineno-4-34"></a>            <span class="n">results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="o">*</span><span class="n">tasks</span><span class="p">)</span>
<a id="__codelineno-4-35" name="__codelineno-4-35" href="#__codelineno-4-35"></a>            <span class="k">return</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">if</span> <span class="n">r</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
</code></pre></div>
<h3 id="342-incremental-update-strategy">3.4.2 Incremental Update Strategy<a class="headerlink" href="#342-incremental-update-strategy" title="Permanent link">¶</a></h3>
<p>Pre-training data is not a one-time task. Over time, new data needs to be continuously absorbed to maintain the timeliness of model knowledge. The key challenges of incremental updates are:</p>
<p><strong>Identifying new data</strong>: For Common Crawl, new batches are released monthly and can be processed directly. For independent crawling, update timestamps need to be maintained, periodically revisiting known URLs to check for updates.</p>
<p><strong>Avoiding duplicate processing</strong>: Already processed data should not re-enter the pipeline. Deduplication can be performed through URL fingerprints, content hashes, and other methods.</p>
<p><strong>Version management</strong>: Each processing batch should have a clear version identifier for traceability and rollback. This is closely related to the data version control (DVC/LakeFS) discussed in Chapter 2.</p>
<h3 id="343-quality-monitoring-and-feedback">3.4.3 Quality Monitoring and Feedback<a class="headerlink" href="#343-quality-monitoring-and-feedback" title="Permanent link">¶</a></h3>
<p>Data acquisition pipelines need to establish comprehensive quality monitoring mechanisms. Key monitoring metrics include:</p>
<p><strong>Download success rate</strong>: Proportion of failed requests. If it suddenly increases, the target website may have blocked the crawler.</p>
<p><strong>Parsing success rate</strong>: Proportion of successful body text extractions. If it decreases, the target website may have changed its page structure.</p>
<p><strong>Average document length</strong>: Average character count of body text. Abnormal fluctuations may indicate parser problems.</p>
<p><strong>Language distribution</strong>: Proportion of data in each language. Ensure it matches the expected language ratio.</p>
<p><strong>Duplication rate</strong>: Proportion of duplication with historical data. An excessively high duplication rate means the marginal value of new data is declining.</p>
<p>It is recommended to integrate these metrics into monitoring systems (such as Prometheus + Grafana), set alert thresholds, and promptly detect and handle anomalies.</p>
<hr>
<h2 id="35-common-pitfalls-and-best-practices">3.5 Common Pitfalls and Best Practices<a class="headerlink" href="#35-common-pitfalls-and-best-practices" title="Permanent link">¶</a></h2>
<p>In the data acquisition phase, several common pitfalls deserve caution.</p>
<p><strong>The first pitfall is over-reliance on a single data source.</strong> If pre-training data all comes from Common Crawl, the model may inherit the biases and noise of web data. A reasonable approach is to mix multiple sources: web data provides breadth, books and papers provide depth, and code data provides logical capabilities. The Pile-style multi-source mixing strategy has proven effective.</p>
<p><strong>The second pitfall is ignoring data timeliness.</strong> Historical batches of Common Crawl, though voluminous, may contain outdated information. For applications requiring timeliness (such as news and current events), more recent data batches should be prioritized. Additionally, very old data may contain defunct links, corrected erroneous information, etc.</p>
<p><strong>The third pitfall is underestimating compliance risks.</strong> Copyright issues, privacy issues, robots.txt violations, etc., may trigger serious legal problems in later project stages. The best practice is to establish comprehensive metadata records during the data acquisition phase—recording each data item's source URL, acquisition time, claimed license, and other information, leaving evidence for possible future audits.</p>
<p><strong>The fourth pitfall is emphasizing collection over processing.</strong> Many teams expend great effort expanding data collection scale but rush through parsing and cleaning steps. As stated in Chapter 1, data quality is far more important than data quantity. It's better to collect less data but ensure each piece undergoes strict quality control.</p>
<hr>
<h2 id="36-chapter-summary">3.6 Chapter Summary<a class="headerlink" href="#36-chapter-summary" title="Permanent link">¶</a></h2>
<p>This chapter systematically introduces the methodology and engineering practices of pre-training data acquisition.</p>
<p>In terms of open-source datasets, Common Crawl is the most important upstream data source, providing three formats: WARC, WAT, and WET. RefinedWeb and The Pile are carefully processed high-quality datasets whose processing methods are worth learning from. Chinese datasets are relatively scarce, often requiring independent extraction from Common Crawl.</p>
<p>In terms of web parsing, Trafilatura is currently the most recommended industrial-grade parsing library, capable of accurately extracting body content from complex HTML. Distributed parsing architectures (such as based on Ray Data) are necessary for processing TB-level data.</p>
<p>In terms of specialized data, code data can be acquired through The Stack or GitHub BigQuery, with attention to license compliance; academic papers can be acquired through ArXiv and S2ORC; book data carries higher copyright risks, and public domain resources are recommended. Multilingual data needs to be balanced through strategies like temperature sampling.</p>
<p>In terms of engineering practices, a complete data acquisition pipeline needs to consider crawler architecture design, incremental update strategies, and quality monitoring mechanisms. Core principles are multi-source mixing, quality first, and compliance foremost.</p>
<p><a class="glightbox" data-type="image" data-width="auto" data-height="auto" href="../../../images/part2/%E5%9B%BE3_5_%E6%9C%AC%E7%AB%A0%E7%9F%A5%E8%AF%86%E7%BB%93%E6%9E%84.png" data-desc-position="bottom"><img alt="Figure 3-5: Chapter Knowledge Structure" src="../../../images/part2/%E5%9B%BE3_5_%E6%9C%AC%E7%AB%A0%E7%9F%A5%E8%AF%86%E7%BB%93%E6%9E%84.png"></a></p>
<p><em>Figure 3-5: Chapter 3 Knowledge Structure — Covering four major themes: open-source datasets, web parsing, specialized data, and engineering practices</em></p>
<hr>
<h2 id="further-reading">Further Reading<a class="headerlink" href="#further-reading" title="Permanent link">¶</a></h2>
<p>For in-depth content on pre-training data acquisition, the following resources are worth consulting:</p>
<p>Common Crawl official documentation (commoncrawl.org/the-data) provides detailed introductions to data formats and acquisition methods. The RefinedWeb paper (Falcon LLM: A Large Language Model for High-Quality Web Data) details the complete process of building high-quality pre-training sets from Common Crawl. The Pile paper (The Pile: An 800GB Dataset of Diverse Text for Language Modeling) introduces multi-source mixed data construction strategies. Trafilatura documentation (trafilatura.readthedocs.io) provides comprehensive API documentation and usage examples. The Stack paper (StarCoder: May the Source Be with You!) introduces methods for building large-scale code datasets.</p>
<hr>
<h2 id="next-chapter-preview">Next Chapter Preview<a class="headerlink" href="#next-chapter-preview" title="Permanent link">¶</a></h2>
<p>Acquiring raw data is only the first step. In the next chapter, "Cleaning and Denoising," we will delve into how to screen high-quality content from massive raw data. You will learn heuristic filtering rules (language identification, perplexity filtering, length distribution), large-scale deduplication techniques (principles and distributed implementation of MinHash LSH), and privacy data cleaning (PII identification and removal).</p>
<p>Enter the next chapter with this question: If two documents have 80% identical content, how can you efficiently identify and handle them?</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer">
        
          
          <a href="../../part1/1_2_data_infra/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Chapter 2: Data Infrastructure Selection">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Chapter 2: Data Infrastructure Selection
              </div>
            </div>
          </a>
        
        
          
          <a href="../2_2_cleaning_denoising/" class="md-footer__link md-footer__link--next" aria-label="Next: Chapter 4: Cleaning &amp; Deduplication">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Chapter 4: Cleaning &amp; Deduplication
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.sections", "navigation.expand", "navigation.indexes", "navigation.top", "navigation.footer", "toc.follow", "search.suggest", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>